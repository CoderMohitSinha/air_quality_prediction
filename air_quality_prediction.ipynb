{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Air+Quality\n",
    "\n",
    "Attribute Information:\n",
    "* 0 Date\t(DD/MM/YYYY) \n",
    "* 1 Time\t(HH.MM.SS) \n",
    "* 2 True hourly averaged concentration CO in mg/m^3 (reference analyzer) \n",
    "* 3 PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)\t\n",
    "* 4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer) \n",
    "* 5 True hourly averaged Benzene concentration in microg/m^3 (reference analyzer) \n",
    "* 6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\t\n",
    "* 7 True hourly averaged NOx concentration in ppb (reference analyzer) \n",
    "* 8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) \n",
    "* 9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\t\n",
    "* 10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\t\n",
    "* 11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted) \n",
    "* 12 Temperature in Â°C\t\n",
    "* 13 Relative Humidity (%) \n",
    "* 14 AH Absolute Humidity \n",
    "\n",
    "**Missing values are tagged with -200 value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libaray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* Drop Datetime feature column (the order already contain time series information)\n",
    "* Drop all-nan rows and columns\n",
    "* Convert string type into float type\n",
    "* Calculate how many -200(nan) exists in each column, and drop the column which contains too many missing data\n",
    "* Missing Data Imputation: (1) Plot correlation matrix(after filter -200 value) (2) Use Linear Regression to imputate missing data with high correlation feature (3) If regression score is smaller than 0.8, use mean instead of regression result\n",
    "* Since EPA Administrator uses CO, NO2, PM2.5, PM10, O3, SO2 as standard of Air Quality Index and use maximum of their conversion as the AQI value, CO and NO2 are selected as air quality definition which is max(AQI(CO),AQI(NO2))\n",
    "* EPA Administrator evaluates the concentration of CO on 8 hourly average, so the values are assigned with 8 hourly average value\n",
    "* Plot quartiles graph to see if there are many outliers in CO and NO2 data. CO and NO2 has 301 and 380 outliers, respectively. Since it only account for a few ratio, it is no need for removing. Also, when we see the exact value, they are in common range of AQI.\n",
    "* The time series curve is also be plotted. The plot of change of CO is more clear than the plot of NO2. NO2's curve seems to be more dramatical.\n",
    "* Convert the concentration of CO and NO2 into their AQI However, we can see that only few CO's index is larger than NO2's index. Therefore, after AQI column is built, NO2 column is removed because we don't need too highly similar columns to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrain(filename, skipped):\n",
    "    train = pd.read_csv(filename, sep=';',usecols=lambda x: x not in skipped)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_skip = ['Date','Time']\n",
    "df = readTrain('air_data.csv', columns_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='all')\n",
    "df = df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(type(df[c][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if c!='Date' and c!='Time' and isinstance(df[c][0], str):\n",
    "        df[c] = df[c].apply(lambda x: float(x.replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "nan_row = {'CO(GT)':0,'PT08.S1(CO)':0,'NMHC(GT)':0,'C6H6(GT)':0,'PT08.S2(NMHC)':0,'NOx(GT)':0,'PT08.S3(NOx)':0,'NO2(GT)':0,'PT08.S4(NO2)':0,'PT08.S5(O3)':0,'T':0,'RH':0,'AH':0}\n",
    "for index, row in df.iterrows():\n",
    "    for c in nan_row.keys():\n",
    "        if row[c]==-200:\n",
    "            nan_row[c]+=1\n",
    "            idx.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CO(GT)': 1683,\n",
       " 'PT08.S1(CO)': 366,\n",
       " 'NMHC(GT)': 8443,\n",
       " 'C6H6(GT)': 366,\n",
       " 'PT08.S2(NMHC)': 366,\n",
       " 'NOx(GT)': 1639,\n",
       " 'PT08.S3(NOx)': 366,\n",
       " 'NO2(GT)': 1642,\n",
       " 'PT08.S4(NO2)': 366,\n",
       " 'PT08.S5(O3)': 366,\n",
       " 'T': 366,\n",
       " 'RH': 366,\n",
       " 'AH': 366}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['NMHC(GT)'])\n",
    "df_ = df.drop(list(set(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = list(df_.columns)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(df_.corr(), interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels(['']+alpha)\n",
    "ax.set_yticklabels(['']+alpha)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RH               0.105157\n",
      "AH               0.295591\n",
      "T                0.318261\n",
      "PT08.S3(NOx)     0.823728\n",
      "NO2(GT)          0.861432\n",
      "PT08.S5(O3)      0.882943\n",
      "PT08.S1(CO)      0.936261\n",
      "PT08.S4(NO2)     0.939921\n",
      "NOx(GT)          0.951342\n",
      "PT08.S2(NMHC)    0.958426\n",
      "C6H6(GT)         0.972660\n",
      "CO(GT)           1.000000\n",
      "Name: CO(GT), dtype: float64\n",
      "RH               0.039570\n",
      "T                0.324815\n",
      "AH               0.407038\n",
      "PT08.S3(NOx)     0.829577\n",
      "NO2(GT)          0.866579\n",
      "NOx(GT)          0.922885\n",
      "C6H6(GT)         0.931368\n",
      "PT08.S5(O3)      0.935011\n",
      "CO(GT)           0.936261\n",
      "PT08.S2(NMHC)    0.936346\n",
      "PT08.S4(NO2)     0.945020\n",
      "PT08.S1(CO)      1.000000\n",
      "Name: PT08.S1(CO), dtype: float64\n",
      "RH               0.178410\n",
      "AH               0.313415\n",
      "T                0.418409\n",
      "NO2(GT)          0.846743\n",
      "PT08.S3(NOx)     0.848850\n",
      "PT08.S5(O3)      0.896978\n",
      "NOx(GT)          0.927304\n",
      "PT08.S1(CO)      0.931368\n",
      "PT08.S4(NO2)     0.960811\n",
      "CO(GT)           0.972660\n",
      "PT08.S2(NMHC)    0.984834\n",
      "C6H6(GT)         1.000000\n",
      "Name: C6H6(GT), dtype: float64\n",
      "RH               0.193333\n",
      "AH               0.325333\n",
      "T                0.445615\n",
      "NO2(GT)          0.885023\n",
      "PT08.S5(O3)      0.909100\n",
      "PT08.S3(NOx)     0.910651\n",
      "NOx(GT)          0.926633\n",
      "PT08.S1(CO)      0.936346\n",
      "PT08.S4(NO2)     0.957883\n",
      "CO(GT)           0.958426\n",
      "C6H6(GT)         0.984834\n",
      "PT08.S2(NMHC)    1.000000\n",
      "Name: PT08.S2(NMHC), dtype: float64\n",
      "RH               0.041975\n",
      "T                0.238395\n",
      "AH               0.270679\n",
      "PT08.S3(NOx)     0.814297\n",
      "NO2(GT)          0.857425\n",
      "PT08.S5(O3)      0.893381\n",
      "PT08.S4(NO2)     0.912724\n",
      "PT08.S1(CO)      0.922885\n",
      "PT08.S2(NMHC)    0.926633\n",
      "C6H6(GT)         0.927304\n",
      "CO(GT)           0.951342\n",
      "NOx(GT)          1.000000\n",
      "Name: NOx(GT), dtype: float64\n",
      "RH               0.096834\n",
      "T                0.423946\n",
      "AH               0.463016\n",
      "NOx(GT)          0.814297\n",
      "NO2(GT)          0.815224\n",
      "CO(GT)           0.823728\n",
      "PT08.S1(CO)      0.829577\n",
      "C6H6(GT)         0.848850\n",
      "PT08.S5(O3)      0.857526\n",
      "PT08.S4(NO2)     0.880213\n",
      "PT08.S2(NMHC)    0.910651\n",
      "PT08.S3(NOx)     1.000000\n",
      "Name: PT08.S3(NOx), dtype: float64\n",
      "AH               0.214559\n",
      "RH               0.223033\n",
      "T                0.406807\n",
      "PT08.S4(NO2)     0.807792\n",
      "PT08.S3(NOx)     0.815224\n",
      "PT08.S5(O3)      0.839656\n",
      "C6H6(GT)         0.846743\n",
      "NOx(GT)          0.857425\n",
      "CO(GT)           0.861432\n",
      "PT08.S1(CO)      0.866579\n",
      "PT08.S2(NMHC)    0.885023\n",
      "NO2(GT)          1.000000\n",
      "Name: NO2(GT), dtype: float64\n",
      "RH               0.012389\n",
      "T                0.343626\n",
      "AH               0.515530\n",
      "NO2(GT)          0.807792\n",
      "PT08.S3(NOx)     0.880213\n",
      "NOx(GT)          0.912724\n",
      "PT08.S5(O3)      0.918996\n",
      "CO(GT)           0.939921\n",
      "PT08.S1(CO)      0.945020\n",
      "PT08.S2(NMHC)    0.957883\n",
      "C6H6(GT)         0.960811\n",
      "PT08.S4(NO2)     1.000000\n",
      "Name: PT08.S4(NO2), dtype: float64\n",
      "RH               0.014530\n",
      "T                0.313458\n",
      "AH               0.440198\n",
      "NO2(GT)          0.839656\n",
      "PT08.S3(NOx)     0.857526\n",
      "CO(GT)           0.882943\n",
      "NOx(GT)          0.893381\n",
      "C6H6(GT)         0.896978\n",
      "PT08.S2(NMHC)    0.909100\n",
      "PT08.S4(NO2)     0.918996\n",
      "PT08.S1(CO)      0.935011\n",
      "PT08.S5(O3)      1.000000\n",
      "Name: PT08.S5(O3), dtype: float64\n",
      "AH               0.159964\n",
      "NOx(GT)          0.238395\n",
      "PT08.S5(O3)      0.313458\n",
      "CO(GT)           0.318261\n",
      "PT08.S1(CO)      0.324815\n",
      "PT08.S4(NO2)     0.343626\n",
      "NO2(GT)          0.406807\n",
      "C6H6(GT)         0.418409\n",
      "PT08.S3(NOx)     0.423946\n",
      "PT08.S2(NMHC)    0.445615\n",
      "RH               0.769869\n",
      "T                1.000000\n",
      "Name: T, dtype: float64\n",
      "PT08.S4(NO2)     0.012389\n",
      "PT08.S5(O3)      0.014530\n",
      "PT08.S1(CO)      0.039570\n",
      "NOx(GT)          0.041975\n",
      "PT08.S3(NOx)     0.096834\n",
      "CO(GT)           0.105157\n",
      "C6H6(GT)         0.178410\n",
      "PT08.S2(NMHC)    0.193333\n",
      "NO2(GT)          0.223033\n",
      "AH               0.475776\n",
      "T                0.769869\n",
      "RH               1.000000\n",
      "Name: RH, dtype: float64\n",
      "T                0.159964\n",
      "NO2(GT)          0.214559\n",
      "NOx(GT)          0.270679\n",
      "CO(GT)           0.295591\n",
      "C6H6(GT)         0.313415\n",
      "PT08.S2(NMHC)    0.325333\n",
      "PT08.S1(CO)      0.407038\n",
      "PT08.S5(O3)      0.440198\n",
      "PT08.S3(NOx)     0.463016\n",
      "RH               0.475776\n",
      "PT08.S4(NO2)     0.515530\n",
      "AH               1.000000\n",
      "Name: AH, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for c in df_.columns:\n",
    "    print(tmp[c].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find highest correlation feature for each\n",
    "pair=[['CO(GT)','C6H6(GT)'],\\\n",
    "     ['PT08.S1(CO)','PT08.S4(NO2)'],\\\n",
    "     ['C6H6(GT)','PT08.S2(NMHC)'],\\\n",
    "     ['PT08.S2(NMHC)','C6H6(GT)'],\\\n",
    "     ['NOx(GT)','CO(GT)'],\\\n",
    "     ['PT08.S3(NOx)','PT08.S2(NMHC)'],\\\n",
    "     ['NO2(GT)','PT08.S2(NMHC)'],\\\n",
    "     ['PT08.S4(NO2)','C6H6(GT)'],\\\n",
    "     ['PT08.S5(O3)','PT08.S1(CO)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CO(GT)', 'C6H6(GT)']\n",
      "0.8669068473182029\n",
      "['PT08.S1(CO)', 'PT08.S4(NO2)']\n",
      "0.46632679816621436\n",
      "['C6H6(GT)', 'PT08.S2(NMHC)']\n",
      "0.9642264227022088\n",
      "['PT08.S2(NMHC)', 'C6H6(GT)']\n",
      "0.9642264227022088\n",
      "['NOx(GT)', 'CO(GT)']\n",
      "0.6320702354277932\n",
      "['PT08.S3(NOx)', 'PT08.S2(NMHC)']\n",
      "0.6347362813041744\n",
      "['NO2(GT)', 'PT08.S2(NMHC)']\n",
      "0.4176329650224425\n",
      "['PT08.S4(NO2)', 'C6H6(GT)']\n",
      "0.5863445130410294\n",
      "['PT08.S5(O3)', 'PT08.S1(CO)']\n",
      "0.8087827962217311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "miss = dict.fromkeys(df.columns)\n",
    "score = dict.fromkeys(df.columns)\n",
    "for p in pair:\n",
    "    print(p)\n",
    "    df_tmp = pd.DataFrame(df, columns=p)\n",
    "    df_tmp = df_tmp.loc[df_tmp[p[0]]!=-200]\n",
    "    df_tmp = df_tmp.loc[df_tmp[p[1]]!=-200]\n",
    "    \n",
    "    X = np.array(list(df_tmp[p[1]])).reshape(-1, 1)\n",
    "    y = np.array(list(df_tmp[p[0]])).reshape(-1, 1)\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    score[p[0]] = reg.score(X,y)\n",
    "    print(reg.score(X,y))\n",
    "    \n",
    "    df_tmp = pd.DataFrame(df, columns=p)\n",
    "    df_tmp = df_tmp.loc[df_tmp[p[0]] ==-200]\n",
    "    miss[p[0]] = reg.predict(np.array(list(df_tmp[p[1]])).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if reg score is higher than 0.8, assign the values\n",
    "for c in df.columns:\n",
    "    if score[c] and score[c]>=0.8:\n",
    "        x = 0\n",
    "        for i in range(len(df)):\n",
    "            if df[c][i]==-200:\n",
    "                df.loc[i,p[0]] = miss[c][x]\n",
    "                x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if reg score is smaller than 0.8, assign the mean of the feature\n",
    "for c in df.columns:\n",
    "    count = 0\n",
    "    for x in list(df[c]):\n",
    "        if x==-200:\n",
    "            count+=1\n",
    "    fake_mean = np.mean(df[c])\n",
    "    true_mean = (fake_mean*len(df)-(-200)*count)/(len(df)-nan_row[c])\n",
    "    df[c] = df[c].apply(lambda x: true_mean if x == -200 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take CO and NO2 as targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign CO's value with 8 hourly average value\n",
    "for i in range(len(df)):\n",
    "    if i<8:\n",
    "        df.loc[i,'CO(GT)'] = np.mean(df['CO(GT)'][:i+1])\n",
    "    else:\n",
    "        df.loc[i,'CO(GT)'] = np.mean(df['CO(GT)'][i-8:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efeb108e128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=df['CO(GT)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = sorted(list(df['CO(GT)']))\n",
    "Q1 = (co[int(0.25*len(co))]+co[int(0.25*len(co))+1])/2\n",
    "Q3 = (co[int(0.75*len(co))]+co[int(0.75*len(co))+1])/2\n",
    "outlier_top = Q3+(Q3-Q1)*1.5\n",
    "outlier_buttom = Q1-(Q3-Q1)*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9242777055787319 3.323680323992303\n"
     ]
    }
   ],
   "source": [
    "print(outlier_buttom, outlier_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print number of outlier\n",
    "sum(1 for i in co if i > outlier_top)+sum(1 for i in co if i < outlier_buttom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efeac8c5978>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=df['NO2(GT)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2 = sorted(list(df['NO2(GT)']))\n",
    "Q1 = (no2[int(0.25*len(no2))]+no2[int(0.25*len(no2))+1])/2\n",
    "Q3 = (no2[int(0.75*len(no2))]+no2[int(0.75*len(no2))+1])/2\n",
    "outlier_buttom = Q1-(Q3-Q1)*1.5\n",
    "outlier_top = Q3+(Q3-Q1)*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5 203.5\n"
     ]
    }
   ],
   "source": [
    "print(outlier_buttom, outlier_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for i in no2 if i > outlier_top)+sum(1 for i in no2 if i < outlier_buttom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efea9974e10>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(df)),df['CO(GT)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efea9952438>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "plt.plot(range(len(df)),normalize(np.array(df['NO2(GT)']).reshape(-1,1),axis=0).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The standard AQI of EPA Administrator \n",
    "|AQI|CO|NO2|\n",
    "|---|---|---|\n",
    "|0～50|0 - 4.4|0 - 53|\n",
    "|51～100|4.5 - 9.4|54 - 100|\n",
    "|101～150|9.5 - 12.4|101 - 360|\n",
    "|151～200|12.5 - 15.4|361 - 649|\n",
    "|201～300|15.5 - 30.4|650 - 1249|\n",
    "|301～400|30.5 - 40.4|1250 - 1649|\n",
    "|401～500|40.5 - 50.4|1650 - 2049|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the value to AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = {'AQI':[0,51,101,151,201,301,401,501],\n",
    "       'CO':[0,4.5,9.5,12.5,15.5,30.5,40.5,50.5],\n",
    "       'NO2':[0,54,101,361,650,1250,1650,2050]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_intercept = {'CO':[],'NO2':[]}\n",
    "for i in range(1,len(MAP['AQI'])):\n",
    "    cx1 = MAP['CO'][i-1]\n",
    "    nx1 = MAP['NO2'][i-1]\n",
    "    y1 = MAP['AQI'][i-1]\n",
    "    cx2 = MAP['CO'][i]-0.1\n",
    "    nx2 = MAP['NO2'][i]-1\n",
    "    y2 = MAP['AQI'][i]-1\n",
    "    ca = (y2-y1)/(cx2-cx1)\n",
    "    cb = y1-ca*cx1\n",
    "    na = (y2-y1)/(nx2-nx1)\n",
    "    nb = y1-na*nx1\n",
    "    slope_intercept['CO'].append((ca,cb))\n",
    "    slope_intercept['NO2'].append((na,nb))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CO': [(11.363636363636363, 0.0),\n",
       "  (10.0, 6.0),\n",
       "  (16.89655172413793, -59.51724137931032),\n",
       "  (16.89655172413793, -60.2068965517241),\n",
       "  (6.644295302013424, 98.01342281879194),\n",
       "  (10.000000000000002, -4.000000000000057),\n",
       "  (10.000000000000002, -4.000000000000057)],\n",
       " 'NO2': [(0.9433962264150944, 0.0),\n",
       "  (1.065217391304348, -6.5217391304347885),\n",
       "  (0.1891891891891892, 81.89189189189189),\n",
       "  (0.1701388888888889, 89.57986111111111),\n",
       "  (0.1652754590984975, 93.57095158597663),\n",
       "  (0.24812030075187969, -9.150375939849596),\n",
       "  (0.24812030075187969, -8.398496240601503)]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_interval(s, f):\n",
    "    for i in range(1,len(MAP[s])):\n",
    "        if f<MAP[s][i]:\n",
    "            return i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = list(df['CO(GT)'])\n",
    "no2 = list(df['NO2(GT)'])\n",
    "aqi = []\n",
    "caqi = []\n",
    "naqi = []\n",
    "count = 0\n",
    "for i in range(len(co)):\n",
    "    ca, cb = slope_intercept['CO'][return_interval('CO',co[i])]\n",
    "    na, nb = slope_intercept['NO2'][return_interval('NO2',no2[i])]\n",
    "    c = ca*co[i]+cb\n",
    "    n = na*no2[i]+nb\n",
    "    caqi.append(c)\n",
    "    naqi.append(n)\n",
    "    MAX = max(c,n)\n",
    "    aqi.append(MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for i in range(len(aqi)) if aqi[i]!=naqi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(len(df.columns), \"AQI\", aqi, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['NO2(GT)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.600000</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>103.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.300000</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>91.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.366667</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>103.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.366667</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>104.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.246667</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>103.837838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CO(GT)  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  \\\n",
       "0  2.600000       1360.0      11.9         1046.0    166.0        1056.0   \n",
       "1  2.300000       1292.0       9.4          955.0    103.0        1174.0   \n",
       "2  2.366667       1402.0       9.0          939.0    131.0        1140.0   \n",
       "3  2.366667       1376.0       9.2          948.0    172.0        1092.0   \n",
       "4  2.246667       1272.0       6.5          836.0    131.0        1205.0   \n",
       "\n",
       "   PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH         AQI  \n",
       "0        1692.0       1268.0  13.6  48.9  0.7578  103.270270  \n",
       "1        1559.0        972.0  13.3  47.7  0.7255   91.478261  \n",
       "2        1555.0       1074.0  11.9  54.0  0.7502  103.459459  \n",
       "3        1584.0       1203.0  11.0  60.0  0.7867  104.972973  \n",
       "4        1490.0       1110.0  11.2  59.6  0.7888  103.837838  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model\n",
    "* Given previous 5-day data(input), we would like to predict AQI of the next 5 days(output)\n",
    "* Use RNN(with LSTM) model to learn the time series pattern and predict the AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastHour=120, futureHour=120):\n",
    "    XX, yy = [], []\n",
    "    from sklearn.preprocessing import normalize\n",
    "    from sklearn.utils import shuffle\n",
    "    for i in range(train.shape[0]-futureHour-pastHour):\n",
    "        x = np.array(train.iloc[i:i+pastHour])\n",
    "        x = normalize(x, axis=1)\n",
    "        XX.append(x)\n",
    "        yy.append(np.array(train.iloc[i+pastHour:i+pastHour+futureHour][\"AQI\"]))\n",
    "    XX, yy = shuffle(XX, yy)\n",
    "    return np.array(XX[:int(len(XX)*0.7)]), np.array(yy[:int(len(yy)*0.7)]), np.array(XX[int(len(XX)*0.7):]), np.array(yy[int(len(yy)*0.7):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X,Y,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildManyToManyModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(13, input_length=shape[1], input_dim=shape[2], return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.add(Lambda(lambda x: x[:, -5*24:, :]))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readTrain('data.csv', [])\n",
    "X_train, y_train, X_test, y_test = buildTrain(df, 5*24, 5*24)\n",
    "splits = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(13, return_sequences=True, input_shape=(120, 13))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 120, 13)           1404      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 120, 1)            14        \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 120, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,418\n",
      "Trainable params: 1,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4466 samples, validate on 1915 samples\n",
      "Epoch 1/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 9229.8265 - val_loss: 9134.4516\n",
      "Epoch 2/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 9004.6951 - val_loss: 8851.2108\n",
      "Epoch 3/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 8715.3694 - val_loss: 8554.9755\n",
      "Epoch 4/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8448.8780 - val_loss: 8357.7537\n",
      "Epoch 5/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8299.2935 - val_loss: 8232.3036\n",
      "Epoch 6/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8179.4621 - val_loss: 8117.8651\n",
      "Epoch 7/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8070.5855 - val_loss: 8014.7008\n",
      "Epoch 8/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7969.8838 - val_loss: 7916.4131\n",
      "Epoch 9/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7873.2833 - val_loss: 7821.4139\n",
      "Epoch 10/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7779.6462 - val_loss: 7729.1238\n",
      "Epoch 11/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7688.4178 - val_loss: 7638.9911\n",
      "Epoch 12/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7599.1630 - val_loss: 7550.7317\n",
      "Epoch 13/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7511.6714 - val_loss: 7464.0848\n",
      "Epoch 14/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7425.7099 - val_loss: 7378.8898\n",
      "Epoch 15/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7341.1447 - val_loss: 7295.0067\n",
      "Epoch 16/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7257.8758 - val_loss: 7212.2530\n",
      "Epoch 17/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7175.7202 - val_loss: 7130.7229\n",
      "Epoch 18/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7094.6754 - val_loss: 7050.2032\n",
      "Epoch 19/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7014.6228 - val_loss: 6970.7036\n",
      "Epoch 20/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6935.5580 - val_loss: 6892.0816\n",
      "Epoch 21/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6857.4175 - val_loss: 6814.3944\n",
      "Epoch 22/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6780.1771 - val_loss: 6737.6875\n",
      "Epoch 23/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6703.8608 - val_loss: 6661.8067\n",
      "Epoch 24/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6628.3870 - val_loss: 6586.7315\n",
      "Epoch 25/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6553.7518 - val_loss: 6512.4263\n",
      "Epoch 26/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6479.8541 - val_loss: 6439.0392\n",
      "Epoch 27/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6406.7833 - val_loss: 6366.3412\n",
      "Epoch 28/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6334.4324 - val_loss: 6294.3846\n",
      "Epoch 29/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6262.8185 - val_loss: 6223.0687\n",
      "Epoch 30/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6191.8581 - val_loss: 6152.5569\n",
      "Epoch 31/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6121.6601 - val_loss: 6082.5839\n",
      "Epoch 32/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6052.0471 - val_loss: 6013.4894\n",
      "Epoch 33/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5983.2313 - val_loss: 5944.8129\n",
      "Epoch 34/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5914.9408 - val_loss: 5876.9798\n",
      "Epoch 35/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5847.3512 - val_loss: 5809.7418\n",
      "Epoch 36/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5780.3997 - val_loss: 5743.0404\n",
      "Epoch 37/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5714.0311 - val_loss: 5677.0475\n",
      "Epoch 38/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5648.3215 - val_loss: 5611.6329\n",
      "Epoch 39/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5583.2297 - val_loss: 5546.8154\n",
      "Epoch 40/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5518.7117 - val_loss: 5482.7306\n",
      "Epoch 41/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5454.8759 - val_loss: 5419.1265\n",
      "Epoch 42/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5391.5947 - val_loss: 5356.1510\n",
      "Epoch 43/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5328.9035 - val_loss: 5293.8179\n",
      "Epoch 44/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5266.8542 - val_loss: 5231.9751\n",
      "Epoch 45/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5205.3254 - val_loss: 5170.8267\n",
      "Epoch 46/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5144.4143 - val_loss: 5110.2297\n",
      "Epoch 47/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5084.0689 - val_loss: 5050.1739\n",
      "Epoch 48/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5024.2985 - val_loss: 4990.6099\n",
      "Epoch 49/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4965.0457 - val_loss: 4931.6718\n",
      "Epoch 50/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4906.3686 - val_loss: 4873.2741\n",
      "Epoch 51/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4848.2248 - val_loss: 4815.4369\n",
      "Epoch 52/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4790.6195 - val_loss: 4758.1536\n",
      "Epoch 53/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4733.5781 - val_loss: 4701.2819\n",
      "Epoch 54/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4676.9954 - val_loss: 4645.0434\n",
      "Epoch 55/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4620.9725 - val_loss: 4589.2903\n",
      "Epoch 56/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4565.4770 - val_loss: 4533.9863\n",
      "Epoch 57/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4510.4528 - val_loss: 4479.2655\n",
      "Epoch 58/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4455.9676 - val_loss: 4425.0113\n",
      "Epoch 59/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4401.9540 - val_loss: 4371.3073\n",
      "Epoch 60/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4348.4530 - val_loss: 4318.0872\n",
      "Epoch 61/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4295.4689 - val_loss: 4265.2800\n",
      "Epoch 62/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4242.9279 - val_loss: 4213.0415\n",
      "Epoch 63/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4190.9030 - val_loss: 4161.2711\n",
      "Epoch 64/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4139.3812 - val_loss: 4109.9075\n",
      "Epoch 65/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4088.3003 - val_loss: 4059.0853\n",
      "Epoch 66/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4037.6771 - val_loss: 4008.8433\n",
      "Epoch 67/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3987.5998 - val_loss: 3958.9267\n",
      "Epoch 68/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 3937.9575 - val_loss: 3909.4693\n",
      "Epoch 69/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3888.7415 - val_loss: 3860.6096\n",
      "Epoch 70/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3840.0441 - val_loss: 3812.1517\n",
      "Epoch 71/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 3791.7982 - val_loss: 3764.1214\n",
      "Epoch 72/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 3744.0284 - val_loss: 3716.4847\n",
      "Epoch 73/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3696.6421 - val_loss: 3669.4976\n",
      "Epoch 74/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3649.7982 - val_loss: 3622.8621\n",
      "Epoch 75/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3603.3765 - val_loss: 3576.6772\n",
      "Epoch 76/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3557.4259 - val_loss: 3530.8530\n",
      "Epoch 77/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3511.8697 - val_loss: 3485.5801\n",
      "Epoch 78/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3466.7823 - val_loss: 3440.7754\n",
      "Epoch 79/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3422.1756 - val_loss: 3396.2926\n",
      "Epoch 80/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3377.9540 - val_loss: 3352.3217\n",
      "Epoch 81/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3334.1985 - val_loss: 3308.7638\n",
      "Epoch 82/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3290.8485 - val_loss: 3265.6931\n",
      "Epoch 83/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3247.9668 - val_loss: 3222.9865\n",
      "Epoch 84/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3205.4799 - val_loss: 3180.7562\n",
      "Epoch 85/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3163.4448 - val_loss: 3138.9128\n",
      "Epoch 86/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 3121.8228 - val_loss: 3097.5115\n",
      "Epoch 87/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3080.6195 - val_loss: 3056.5681\n",
      "Epoch 88/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3039.8659 - val_loss: 3015.9960\n",
      "Epoch 89/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2999.4993 - val_loss: 2975.8896\n",
      "Epoch 90/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2959.5810 - val_loss: 2936.1203\n",
      "Epoch 91/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2920.0299 - val_loss: 2896.8519\n",
      "Epoch 92/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2880.9325 - val_loss: 2857.9457\n",
      "Epoch 93/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2842.2344 - val_loss: 2819.4469\n",
      "Epoch 94/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2803.9320 - val_loss: 2781.3931\n",
      "Epoch 95/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2766.0622 - val_loss: 2743.6856\n",
      "Epoch 96/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2728.5827 - val_loss: 2706.3836\n",
      "Epoch 97/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2691.4784 - val_loss: 2669.5701\n",
      "Epoch 98/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2654.8154 - val_loss: 2633.0925\n",
      "Epoch 99/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2618.5362 - val_loss: 2597.0046\n",
      "Epoch 100/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2582.6519 - val_loss: 2561.3208\n",
      "Epoch 101/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2547.1674 - val_loss: 2526.0097\n",
      "Epoch 102/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2512.0463 - val_loss: 2491.1913\n",
      "Epoch 103/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2477.3837 - val_loss: 2456.6166\n",
      "Epoch 104/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2443.0363 - val_loss: 2422.5575\n",
      "Epoch 105/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2409.1387 - val_loss: 2388.7881\n",
      "Epoch 106/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2375.5853 - val_loss: 2355.4654\n",
      "Epoch 107/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2342.4198 - val_loss: 2322.5454\n",
      "Epoch 108/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2309.6707 - val_loss: 2289.9120\n",
      "Epoch 109/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2277.2584 - val_loss: 2257.7053\n",
      "Epoch 110/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2245.2339 - val_loss: 2225.8816\n",
      "Epoch 111/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2213.5813 - val_loss: 2194.4430\n",
      "Epoch 112/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2182.3162 - val_loss: 2163.3416\n",
      "Epoch 113/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2151.4090 - val_loss: 2132.6430\n",
      "Epoch 114/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 2120.8954 - val_loss: 2102.2595\n",
      "Epoch 115/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2090.7181 - val_loss: 2072.3064\n",
      "Epoch 116/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2060.9193 - val_loss: 2042.7374\n",
      "Epoch 117/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2031.5069 - val_loss: 2013.4723\n",
      "Epoch 118/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2002.4291 - val_loss: 1984.6021\n",
      "Epoch 119/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1973.7151 - val_loss: 1956.1124\n",
      "Epoch 120/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1945.3786 - val_loss: 1927.9422\n",
      "Epoch 121/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1917.3744 - val_loss: 1900.1637\n",
      "Epoch 122/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1889.7493 - val_loss: 1872.6847\n",
      "Epoch 123/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1862.4658 - val_loss: 1845.5587\n",
      "Epoch 124/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1835.5264 - val_loss: 1818.8000\n",
      "Epoch 125/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1808.9465 - val_loss: 1792.3906\n",
      "Epoch 126/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 1782.7153 - val_loss: 1766.3288\n",
      "Epoch 127/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1756.8085 - val_loss: 1740.6802\n",
      "Epoch 128/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1731.2918 - val_loss: 1715.2835\n",
      "Epoch 129/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1706.0829 - val_loss: 1690.2600\n",
      "Epoch 130/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1681.2120 - val_loss: 1665.6067\n",
      "Epoch 131/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1656.7170 - val_loss: 1641.2028\n",
      "Epoch 132/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1632.5121 - val_loss: 1617.2223\n",
      "Epoch 133/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1608.6423 - val_loss: 1593.6327\n",
      "Epoch 134/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1585.1587 - val_loss: 1570.2423\n",
      "Epoch 135/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1561.9665 - val_loss: 1547.1877\n",
      "Epoch 136/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1539.1065 - val_loss: 1524.4807\n",
      "Epoch 137/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1516.5733 - val_loss: 1502.1296\n",
      "Epoch 138/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1494.3736 - val_loss: 1480.1028\n",
      "Epoch 139/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1472.4987 - val_loss: 1458.3807\n",
      "Epoch 140/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1450.9433 - val_loss: 1436.9838\n",
      "Epoch 141/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1429.7040 - val_loss: 1415.9194\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1408.7804 - val_loss: 1395.1872\n",
      "Epoch 143/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1388.2104 - val_loss: 1374.6785\n",
      "Epoch 144/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1367.8884 - val_loss: 1354.6314\n",
      "Epoch 145/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1347.9457 - val_loss: 1334.7927\n",
      "Epoch 146/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1328.2523 - val_loss: 1315.3765\n",
      "Epoch 147/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1308.9461 - val_loss: 1296.1155\n",
      "Epoch 148/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1289.8910 - val_loss: 1277.2100\n",
      "Epoch 149/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1271.1269 - val_loss: 1258.7025\n",
      "Epoch 150/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1252.7220 - val_loss: 1240.4005\n",
      "Epoch 151/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1234.5873 - val_loss: 1222.4053\n",
      "Epoch 152/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1216.7471 - val_loss: 1204.7310\n",
      "Epoch 153/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1199.1964 - val_loss: 1187.4033\n",
      "Epoch 154/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1181.9928 - val_loss: 1170.2418\n",
      "Epoch 155/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1165.0267 - val_loss: 1153.4580\n",
      "Epoch 156/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1148.3795 - val_loss: 1136.9612\n",
      "Epoch 157/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1132.0197 - val_loss: 1120.7512\n",
      "Epoch 158/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1115.9449 - val_loss: 1104.8381\n",
      "Epoch 159/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1100.1710 - val_loss: 1089.1735\n",
      "Epoch 160/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1084.6506 - val_loss: 1073.8774\n",
      "Epoch 161/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1069.4488 - val_loss: 1058.7941\n",
      "Epoch 162/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1054.5101 - val_loss: 1043.9949\n",
      "Epoch 163/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1039.8579 - val_loss: 1029.4519\n",
      "Epoch 164/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1025.4658 - val_loss: 1015.2260\n",
      "Epoch 165/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 1011.3719 - val_loss: 1001.2249\n",
      "Epoch 166/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 997.5195 - val_loss: 987.5557\n",
      "Epoch 167/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 983.9406 - val_loss: 974.1930\n",
      "Epoch 168/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 970.6579 - val_loss: 961.0183\n",
      "Epoch 169/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 957.6186 - val_loss: 948.1233\n",
      "Epoch 170/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 944.8597 - val_loss: 935.4504\n",
      "Epoch 171/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 932.3366 - val_loss: 923.0767\n",
      "Epoch 172/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 920.0946 - val_loss: 910.9345\n",
      "Epoch 173/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 908.0812 - val_loss: 899.1229\n",
      "Epoch 174/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 896.3635 - val_loss: 887.4937\n",
      "Epoch 175/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 884.8858 - val_loss: 876.0798\n",
      "Epoch 176/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 873.6220 - val_loss: 865.0235\n",
      "Epoch 177/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 862.6437 - val_loss: 854.1711\n",
      "Epoch 178/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 851.9032 - val_loss: 843.5477\n",
      "Epoch 179/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 841.4022 - val_loss: 833.1626\n",
      "Epoch 180/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 831.1248 - val_loss: 823.0611\n",
      "Epoch 181/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 821.1179 - val_loss: 813.1323\n",
      "Epoch 182/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 811.3227 - val_loss: 803.4628\n",
      "Epoch 183/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 801.7802 - val_loss: 793.9792\n",
      "Epoch 184/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 792.4274 - val_loss: 784.8321\n",
      "Epoch 185/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 783.3502 - val_loss: 775.8447\n",
      "Epoch 186/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 774.4818 - val_loss: 767.0729\n",
      "Epoch 187/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 765.8373 - val_loss: 758.5121\n",
      "Epoch 188/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 757.3996 - val_loss: 750.2098\n",
      "Epoch 189/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 749.1906 - val_loss: 742.1274\n",
      "Epoch 190/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 741.2017 - val_loss: 734.2377\n",
      "Epoch 191/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 733.4191 - val_loss: 726.5534\n",
      "Epoch 192/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 725.8353 - val_loss: 719.1126\n",
      "Epoch 193/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 718.4918 - val_loss: 711.8026\n",
      "Epoch 194/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 711.3078 - val_loss: 704.7769\n",
      "Epoch 195/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 704.3508 - val_loss: 697.9307\n",
      "Epoch 196/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 697.5882 - val_loss: 691.2831\n",
      "Epoch 197/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 691.0270 - val_loss: 684.8100\n",
      "Epoch 198/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 684.6683 - val_loss: 678.4841\n",
      "Epoch 199/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 678.4513 - val_loss: 672.4579\n",
      "Epoch 200/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 672.4802 - val_loss: 666.5326\n",
      "Epoch 201/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 666.6507 - val_loss: 660.8421\n",
      "Epoch 202/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 661.0269 - val_loss: 655.2918\n",
      "Epoch 203/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 655.5674 - val_loss: 649.9386\n",
      "Epoch 204/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 650.3010 - val_loss: 644.7185\n",
      "Epoch 205/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 645.1820 - val_loss: 639.7196\n",
      "Epoch 206/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 640.2726 - val_loss: 634.8038\n",
      "Epoch 207/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 635.4608 - val_loss: 630.2021\n",
      "Epoch 208/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 630.8852 - val_loss: 625.6516\n",
      "Epoch 209/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 626.4360 - val_loss: 621.2710\n",
      "Epoch 210/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 622.1277 - val_loss: 617.1114\n",
      "Epoch 211/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 618.0152 - val_loss: 613.0208\n",
      "Epoch 212/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 614.0385 - val_loss: 609.0655\n",
      "Epoch 213/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 610.1651 - val_loss: 605.3921\n",
      "Epoch 214/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 606.5119 - val_loss: 601.7231\n",
      "Epoch 215/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 602.9480 - val_loss: 598.2469\n",
      "Epoch 216/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 599.5389 - val_loss: 594.9084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 596.2638 - val_loss: 591.7032\n",
      "Epoch 218/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 593.1044 - val_loss: 588.6751\n",
      "Epoch 219/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 590.1186 - val_loss: 585.6681\n",
      "Epoch 220/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 587.2030 - val_loss: 582.8827\n",
      "Epoch 221/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 584.4533 - val_loss: 580.1545\n",
      "Epoch 222/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 581.7976 - val_loss: 577.5833\n",
      "Epoch 223/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 579.2745 - val_loss: 575.1052\n",
      "Epoch 224/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 576.8556 - val_loss: 572.7366\n",
      "Epoch 225/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 574.5490 - val_loss: 570.4755\n",
      "Epoch 226/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 572.3374 - val_loss: 568.3592\n",
      "Epoch 227/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 570.2597 - val_loss: 566.2811\n",
      "Epoch 228/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 568.2449 - val_loss: 564.3632\n",
      "Epoch 229/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 566.3514 - val_loss: 562.5156\n",
      "Epoch 230/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 564.5488 - val_loss: 560.7522\n",
      "Epoch 231/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 562.8323 - val_loss: 559.0839\n",
      "Epoch 232/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 561.2152 - val_loss: 557.4818\n",
      "Epoch 233/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 559.6731 - val_loss: 555.9805\n",
      "Epoch 234/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 558.2115 - val_loss: 554.5772\n",
      "Epoch 235/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 556.8403 - val_loss: 553.2391\n",
      "Epoch 236/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 555.5391 - val_loss: 551.9732\n",
      "Epoch 237/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 554.3061 - val_loss: 550.8004\n",
      "Epoch 238/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 553.1617 - val_loss: 549.6539\n",
      "Epoch 239/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 552.0577 - val_loss: 548.6267\n",
      "Epoch 240/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 551.0428 - val_loss: 547.6277\n",
      "Epoch 241/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 550.0759 - val_loss: 546.7056\n",
      "Epoch 242/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 549.1752 - val_loss: 545.8345\n",
      "Epoch 243/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 548.3322 - val_loss: 545.0056\n",
      "Epoch 244/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 547.5375 - val_loss: 544.2411\n",
      "Epoch 245/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 546.7968 - val_loss: 543.5318\n",
      "Epoch 246/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 546.1076 - val_loss: 542.8673\n",
      "Epoch 247/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 545.4678 - val_loss: 542.2415\n",
      "Epoch 248/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 544.8684 - val_loss: 541.6575\n",
      "Epoch 249/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 544.3053 - val_loss: 541.1365\n",
      "Epoch 250/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 543.7937 - val_loss: 540.6366\n",
      "Epoch 251/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 543.3179 - val_loss: 540.1664\n",
      "Epoch 252/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 542.8709 - val_loss: 539.7509\n",
      "Epoch 253/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.4643 - val_loss: 539.3616\n",
      "Epoch 254/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 542.0863 - val_loss: 539.0005\n",
      "Epoch 255/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 541.7404 - val_loss: 538.6627\n",
      "Epoch 256/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 541.4158 - val_loss: 538.3752\n",
      "Epoch 257/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 541.1300 - val_loss: 538.0797\n",
      "Epoch 258/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.8567 - val_loss: 537.8247\n",
      "Epoch 259/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.6158 - val_loss: 537.5783\n",
      "Epoch 260/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.3850 - val_loss: 537.3757\n",
      "Epoch 261/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.1834 - val_loss: 537.1827\n",
      "Epoch 262/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.9992 - val_loss: 537.0015\n",
      "Epoch 263/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.8292 - val_loss: 536.8413\n",
      "Epoch 264/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6768 - val_loss: 536.6940\n",
      "Epoch 265/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5401 - val_loss: 536.5597\n",
      "Epoch 266/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.4139 - val_loss: 536.4447\n",
      "Epoch 267/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.3016 - val_loss: 536.3444\n",
      "Epoch 268/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.2044 - val_loss: 536.2429\n",
      "Epoch 269/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.1092 - val_loss: 536.1677\n",
      "Epoch 270/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.0306 - val_loss: 536.0881\n",
      "Epoch 271/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.9565 - val_loss: 536.0214\n",
      "Epoch 272/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.8922 - val_loss: 535.9564\n",
      "Epoch 273/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.8333 - val_loss: 535.9054\n",
      "Epoch 274/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.7832 - val_loss: 535.8579\n",
      "Epoch 275/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.7376 - val_loss: 535.8129\n",
      "Epoch 276/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.6967 - val_loss: 535.7761\n",
      "Epoch 277/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.6612 - val_loss: 535.7412\n",
      "Epoch 278/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.6318 - val_loss: 535.7083\n",
      "Epoch 279/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.6024 - val_loss: 535.6859\n",
      "Epoch 280/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.5807 - val_loss: 535.6636\n",
      "Epoch 281/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.5585 - val_loss: 535.6454\n",
      "Epoch 282/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.5430 - val_loss: 535.6242\n",
      "Epoch 283/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.5254 - val_loss: 535.6138\n",
      "Epoch 284/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.5126 - val_loss: 535.5992\n",
      "Epoch 285/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4991 - val_loss: 535.5895\n",
      "Epoch 286/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4921 - val_loss: 535.5808\n",
      "Epoch 287/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4807 - val_loss: 535.5719\n",
      "Epoch 288/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4752 - val_loss: 535.5622\n",
      "Epoch 289/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.4667 - val_loss: 535.5569\n",
      "Epoch 290/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4605 - val_loss: 535.5530\n",
      "Epoch 291/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4559 - val_loss: 535.5475\n",
      "Epoch 292/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4513 - val_loss: 535.5437\n",
      "Epoch 293/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.4480 - val_loss: 535.5412\n",
      "Epoch 294/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.4460 - val_loss: 535.5369\n",
      "Epoch 00294: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(13, return_sequences=True, input_shape=(120, 13))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 120, 13)           1404      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 120, 1)            14        \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 120, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,418\n",
      "Trainable params: 1,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4466 samples, validate on 1915 samples\n",
      "Epoch 1/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 9229.9782 - val_loss: 9076.9680\n",
      "Epoch 2/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 8964.1649 - val_loss: 8752.9377\n",
      "Epoch 3/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8666.8146 - val_loss: 8477.3908\n",
      "Epoch 4/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8392.2420 - val_loss: 8222.1730\n",
      "Epoch 5/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8194.4347 - val_loss: 8091.0418\n",
      "Epoch 6/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8079.6998 - val_loss: 7983.6151\n",
      "Epoch 7/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7975.2720 - val_loss: 7882.6698\n",
      "Epoch 8/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7876.2091 - val_loss: 7785.9480\n",
      "Epoch 9/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7780.8307 - val_loss: 7692.4991\n",
      "Epoch 10/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7688.2902 - val_loss: 7601.5328\n",
      "Epoch 11/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7598.0422 - val_loss: 7512.6174\n",
      "Epoch 12/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7509.7418 - val_loss: 7425.4704\n",
      "Epoch 13/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7423.1136 - val_loss: 7339.8942\n",
      "Epoch 14/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7337.9488 - val_loss: 7255.7521\n",
      "Epoch 15/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7254.1461 - val_loss: 7172.8313\n",
      "Epoch 16/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7171.5390 - val_loss: 7091.1670\n",
      "Epoch 17/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7090.1257 - val_loss: 7010.5359\n",
      "Epoch 18/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7009.7672 - val_loss: 6930.9834\n",
      "Epoch 19/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6930.4314 - val_loss: 6852.4434\n",
      "Epoch 20/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6852.0546 - val_loss: 6774.8434\n",
      "Epoch 21/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6774.6173 - val_loss: 6698.0787\n",
      "Epoch 22/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6698.0345 - val_loss: 6622.2278\n",
      "Epoch 23/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6622.3174 - val_loss: 6547.2138\n",
      "Epoch 24/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6547.4200 - val_loss: 6472.9920\n",
      "Epoch 25/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6473.3368 - val_loss: 6399.5618\n",
      "Epoch 26/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6400.0565 - val_loss: 6326.8639\n",
      "Epoch 27/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6327.4858 - val_loss: 6255.0389\n",
      "Epoch 28/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6255.7099 - val_loss: 6183.8673\n",
      "Epoch 29/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6184.6495 - val_loss: 6113.3904\n",
      "Epoch 30/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6114.2885 - val_loss: 6043.6735\n",
      "Epoch 31/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6044.6304 - val_loss: 5974.6361\n",
      "Epoch 32/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5975.6550 - val_loss: 5906.2502\n",
      "Epoch 33/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5907.3449 - val_loss: 5838.5322\n",
      "Epoch 34/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5839.6858 - val_loss: 5771.4841\n",
      "Epoch 35/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5772.6875 - val_loss: 5705.0264\n",
      "Epoch 36/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5706.3052 - val_loss: 5639.1961\n",
      "Epoch 37/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5640.5308 - val_loss: 5574.0254\n",
      "Epoch 38/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5575.3885 - val_loss: 5509.4458\n",
      "Epoch 39/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5510.8420 - val_loss: 5445.4976\n",
      "Epoch 40/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5446.9210 - val_loss: 5382.1055\n",
      "Epoch 41/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5383.5792 - val_loss: 5319.3465\n",
      "Epoch 42/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5320.8428 - val_loss: 5257.1538\n",
      "Epoch 43/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5258.7116 - val_loss: 5195.4403\n",
      "Epoch 44/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5197.1018 - val_loss: 5134.4178\n",
      "Epoch 45/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5136.1187 - val_loss: 5073.8783\n",
      "Epoch 46/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5075.6486 - val_loss: 5014.0412\n",
      "Epoch 47/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5015.7715 - val_loss: 4954.7793\n",
      "Epoch 48/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4956.5072 - val_loss: 4895.9292\n",
      "Epoch 49/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4897.7182 - val_loss: 4837.7613\n",
      "Epoch 50/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4839.5540 - val_loss: 4780.0145\n",
      "Epoch 51/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4781.8619 - val_loss: 4722.9156\n",
      "Epoch 52/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4724.7800 - val_loss: 4666.2185\n",
      "Epoch 53/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4668.1487 - val_loss: 4610.1974\n",
      "Epoch 54/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4612.1198 - val_loss: 4554.5779\n",
      "Epoch 55/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4556.5443 - val_loss: 4499.6042\n",
      "Epoch 56/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 4501.5434 - val_loss: 4445.0570\n",
      "Epoch 57/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4447.0284 - val_loss: 4391.0269\n",
      "Epoch 58/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4393.0205 - val_loss: 4337.5268\n",
      "Epoch 59/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4339.5104 - val_loss: 4284.5460\n",
      "Epoch 60/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4286.5167 - val_loss: 4232.0077\n",
      "Epoch 61/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4234.0021 - val_loss: 4179.9770\n",
      "Epoch 62/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4181.9689 - val_loss: 4128.4800\n",
      "Epoch 63/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4130.4485 - val_loss: 4077.4354\n",
      "Epoch 64/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4079.4196 - val_loss: 4026.8096\n",
      "Epoch 65/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4028.8169 - val_loss: 3976.7938\n",
      "Epoch 66/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3978.7458 - val_loss: 3927.1897\n",
      "Epoch 67/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3929.1424 - val_loss: 3878.0004\n",
      "Epoch 68/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3879.9841 - val_loss: 3829.3069\n",
      "Epoch 69/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3831.2785 - val_loss: 3781.1557\n",
      "Epoch 70/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3783.0758 - val_loss: 3733.4084\n",
      "Epoch 71/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3735.3304 - val_loss: 3686.0880\n",
      "Epoch 72/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 3688.0481 - val_loss: 3639.1928\n",
      "Epoch 73/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3641.1848 - val_loss: 3592.8413\n",
      "Epoch 74/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3594.7939 - val_loss: 3546.9399\n",
      "Epoch 75/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3548.8754 - val_loss: 3501.4006\n",
      "Epoch 76/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3503.3558 - val_loss: 3456.4099\n",
      "Epoch 77/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3458.3282 - val_loss: 3411.7850\n",
      "Epoch 78/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3413.6912 - val_loss: 3367.6926\n",
      "Epoch 79/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3369.5630 - val_loss: 3323.8998\n",
      "Epoch 80/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3325.8032 - val_loss: 3280.6567\n",
      "Epoch 81/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3282.5298 - val_loss: 3237.7899\n",
      "Epoch 82/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3239.6568 - val_loss: 3195.4002\n",
      "Epoch 83/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3197.2461 - val_loss: 3153.3630\n",
      "Epoch 84/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3155.2163 - val_loss: 3111.8358\n",
      "Epoch 85/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 3113.6526 - val_loss: 3070.6613\n",
      "Epoch 86/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3072.4752 - val_loss: 3029.9576\n",
      "Epoch 87/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3031.7222 - val_loss: 2989.6835\n",
      "Epoch 88/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2991.4120 - val_loss: 2949.7466\n",
      "Epoch 89/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2951.4869 - val_loss: 2910.2450\n",
      "Epoch 90/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2911.9754 - val_loss: 2871.1802\n",
      "Epoch 91/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2872.8750 - val_loss: 2832.5279\n",
      "Epoch 92/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2834.2017 - val_loss: 2794.2325\n",
      "Epoch 93/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2795.9036 - val_loss: 2756.4087\n",
      "Epoch 94/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2758.0213 - val_loss: 2719.0158\n",
      "Epoch 95/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2720.5906 - val_loss: 2681.8724\n",
      "Epoch 96/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2683.4940 - val_loss: 2645.2318\n",
      "Epoch 97/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2646.8299 - val_loss: 2608.9886\n",
      "Epoch 98/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2610.5502 - val_loss: 2573.1858\n",
      "Epoch 99/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 2574.7047 - val_loss: 2537.6994\n",
      "Epoch 100/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2539.2154 - val_loss: 2502.6724\n",
      "Epoch 101/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2504.1534 - val_loss: 2467.9725\n",
      "Epoch 102/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2469.4370 - val_loss: 2433.7623\n",
      "Epoch 103/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2435.1580 - val_loss: 2399.8554\n",
      "Epoch 104/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2401.2443 - val_loss: 2366.3259\n",
      "Epoch 105/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2367.6977 - val_loss: 2333.2377\n",
      "Epoch 106/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2334.5775 - val_loss: 2300.4685\n",
      "Epoch 107/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2301.8199 - val_loss: 2268.0927\n",
      "Epoch 108/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2269.4184 - val_loss: 2236.2031\n",
      "Epoch 109/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2237.4636 - val_loss: 2204.5357\n",
      "Epoch 110/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 2205.8249 - val_loss: 2173.3323\n",
      "Epoch 111/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 2174.5781 - val_loss: 2142.5094\n",
      "Epoch 112/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2143.7018 - val_loss: 2112.0775\n",
      "Epoch 113/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2113.2094 - val_loss: 2081.9787\n",
      "Epoch 114/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2083.0957 - val_loss: 2052.1874\n",
      "Epoch 115/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2053.3169 - val_loss: 2022.8193\n",
      "Epoch 116/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2023.9199 - val_loss: 1993.8238\n",
      "Epoch 117/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1994.8817 - val_loss: 1965.2074\n",
      "Epoch 118/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1966.2178 - val_loss: 1936.9309\n",
      "Epoch 119/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1937.9021 - val_loss: 1909.0209\n",
      "Epoch 120/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1909.9559 - val_loss: 1881.4518\n",
      "Epoch 121/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1882.3598 - val_loss: 1854.2298\n",
      "Epoch 122/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1855.1118 - val_loss: 1827.3718\n",
      "Epoch 123/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1828.2212 - val_loss: 1800.8627\n",
      "Epoch 124/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1801.6899 - val_loss: 1774.6882\n",
      "Epoch 125/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1775.5031 - val_loss: 1748.8640\n",
      "Epoch 126/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1749.6521 - val_loss: 1723.3968\n",
      "Epoch 127/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1724.1472 - val_loss: 1698.2930\n",
      "Epoch 128/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1698.9839 - val_loss: 1673.5536\n",
      "Epoch 129/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1674.1848 - val_loss: 1649.0801\n",
      "Epoch 130/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1649.6998 - val_loss: 1624.9666\n",
      "Epoch 131/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1625.5639 - val_loss: 1601.1742\n",
      "Epoch 132/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1601.7606 - val_loss: 1577.7075\n",
      "Epoch 133/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1578.2688 - val_loss: 1554.6376\n",
      "Epoch 134/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1555.1355 - val_loss: 1531.8727\n",
      "Epoch 135/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1532.3273 - val_loss: 1509.4427\n",
      "Epoch 136/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1509.8531 - val_loss: 1487.3086\n",
      "Epoch 137/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1487.6798 - val_loss: 1465.5583\n",
      "Epoch 138/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 1465.8791 - val_loss: 1444.0315\n",
      "Epoch 139/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1444.3416 - val_loss: 1422.9252\n",
      "Epoch 140/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1423.1615 - val_loss: 1402.0984\n",
      "Epoch 141/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1402.3125 - val_loss: 1381.5171\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1381.7364 - val_loss: 1361.3563\n",
      "Epoch 143/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1361.5173 - val_loss: 1341.4567\n",
      "Epoch 144/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1341.5871 - val_loss: 1321.9130\n",
      "Epoch 145/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1321.9848 - val_loss: 1302.6525\n",
      "Epoch 146/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1302.6882 - val_loss: 1283.6939\n",
      "Epoch 147/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1283.6847 - val_loss: 1265.0780\n",
      "Epoch 148/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1265.0111 - val_loss: 1246.7192\n",
      "Epoch 149/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1246.6280 - val_loss: 1228.6660\n",
      "Epoch 150/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1228.5588 - val_loss: 1210.8755\n",
      "Epoch 151/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1210.7584 - val_loss: 1193.4702\n",
      "Epoch 152/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1193.2877 - val_loss: 1176.3253\n",
      "Epoch 153/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1176.1015 - val_loss: 1159.4785\n",
      "Epoch 154/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1159.2032 - val_loss: 1142.9475\n",
      "Epoch 155/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 1142.6209 - val_loss: 1126.6473\n",
      "Epoch 156/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1126.3094 - val_loss: 1110.6439\n",
      "Epoch 157/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1110.2668 - val_loss: 1095.0185\n",
      "Epoch 158/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1094.5687 - val_loss: 1079.5565\n",
      "Epoch 159/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1079.0839 - val_loss: 1064.4999\n",
      "Epoch 160/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1063.9444 - val_loss: 1049.6187\n",
      "Epoch 161/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1049.0538 - val_loss: 1035.0249\n",
      "Epoch 162/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1034.4323 - val_loss: 1020.7568\n",
      "Epoch 163/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1020.1245 - val_loss: 1006.6918\n",
      "Epoch 164/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1006.0418 - val_loss: 992.9899\n",
      "Epoch 165/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 992.2569 - val_loss: 979.5602\n",
      "Epoch 166/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 978.7583 - val_loss: 966.3299\n",
      "Epoch 167/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 965.5022 - val_loss: 953.3845\n",
      "Epoch 168/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 952.5113 - val_loss: 940.7260\n",
      "Epoch 169/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 939.8111 - val_loss: 928.2604\n",
      "Epoch 170/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 927.3446 - val_loss: 916.0727\n",
      "Epoch 171/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 915.1361 - val_loss: 904.1879\n",
      "Epoch 172/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 903.1856 - val_loss: 892.5850\n",
      "Epoch 173/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 891.5143 - val_loss: 881.1685\n",
      "Epoch 174/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 880.0580 - val_loss: 870.0680\n",
      "Epoch 175/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 868.8791 - val_loss: 859.1694\n",
      "Epoch 176/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 857.9340 - val_loss: 848.5177\n",
      "Epoch 177/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 847.2503 - val_loss: 838.0564\n",
      "Epoch 178/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 836.7653 - val_loss: 827.9427\n",
      "Epoch 179/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 826.5739 - val_loss: 817.9836\n",
      "Epoch 180/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 816.5877 - val_loss: 808.2865\n",
      "Epoch 181/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 806.8615 - val_loss: 798.7761\n",
      "Epoch 182/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 797.3182 - val_loss: 789.6103\n",
      "Epoch 183/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 788.0563 - val_loss: 780.6033\n",
      "Epoch 184/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 779.0097 - val_loss: 771.7925\n",
      "Epoch 185/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 770.1720 - val_loss: 763.2324\n",
      "Epoch 186/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 761.5644 - val_loss: 754.9056\n",
      "Epoch 187/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 753.1808 - val_loss: 746.7872\n",
      "Epoch 188/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 745.0135 - val_loss: 738.8814\n",
      "Epoch 189/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 737.0545 - val_loss: 731.1943\n",
      "Epoch 190/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 729.3183 - val_loss: 723.6954\n",
      "Epoch 191/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 721.7828 - val_loss: 716.4161\n",
      "Epoch 192/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 714.4616 - val_loss: 709.3206\n",
      "Epoch 193/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 707.3281 - val_loss: 702.4617\n",
      "Epoch 194/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 700.3981 - val_loss: 695.8289\n",
      "Epoch 195/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 693.6972 - val_loss: 689.3081\n",
      "Epoch 196/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 687.1512 - val_loss: 683.0261\n",
      "Epoch 197/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 680.8210 - val_loss: 676.9024\n",
      "Epoch 198/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 674.6536 - val_loss: 671.0336\n",
      "Epoch 199/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 668.7109 - val_loss: 665.2752\n",
      "Epoch 200/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 662.9252 - val_loss: 659.7303\n",
      "Epoch 201/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 657.3276 - val_loss: 654.3559\n",
      "Epoch 202/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 651.9131 - val_loss: 649.1433\n",
      "Epoch 203/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 646.6585 - val_loss: 644.1411\n",
      "Epoch 204/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 641.5970 - val_loss: 639.2779\n",
      "Epoch 205/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 636.6994 - val_loss: 634.5647\n",
      "Epoch 206/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 631.9478 - val_loss: 630.0711\n",
      "Epoch 207/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 627.3746 - val_loss: 625.7353\n",
      "Epoch 208/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 622.9592 - val_loss: 621.5496\n",
      "Epoch 209/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 618.7196 - val_loss: 617.4466\n",
      "Epoch 210/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 614.5947 - val_loss: 613.5645\n",
      "Epoch 211/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 610.6614 - val_loss: 609.7597\n",
      "Epoch 212/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 606.8249 - val_loss: 606.2050\n",
      "Epoch 213/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 603.1881 - val_loss: 602.6993\n",
      "Epoch 214/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 599.6504 - val_loss: 599.3871\n",
      "Epoch 215/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 596.2741 - val_loss: 596.1771\n",
      "Epoch 216/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 593.0176 - val_loss: 593.1215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 589.9174 - val_loss: 590.1416\n",
      "Epoch 218/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 586.9060 - val_loss: 587.3611\n",
      "Epoch 219/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 584.0501 - val_loss: 584.6779\n",
      "Epoch 220/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 581.3150 - val_loss: 582.0890\n",
      "Epoch 221/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 578.6848 - val_loss: 579.6400\n",
      "Epoch 222/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 576.1897 - val_loss: 577.2656\n",
      "Epoch 223/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 573.7728 - val_loss: 575.0713\n",
      "Epoch 224/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 571.5034 - val_loss: 572.9279\n",
      "Epoch 225/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 569.3219 - val_loss: 570.8950\n",
      "Epoch 226/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 567.2399 - val_loss: 568.9814\n",
      "Epoch 227/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 565.2684 - val_loss: 567.1504\n",
      "Epoch 228/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 563.3846 - val_loss: 565.4272\n",
      "Epoch 229/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 561.6065 - val_loss: 563.7650\n",
      "Epoch 230/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 559.9046 - val_loss: 562.2113\n",
      "Epoch 231/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 558.3040 - val_loss: 560.7282\n",
      "Epoch 232/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 556.7768 - val_loss: 559.3368\n",
      "Epoch 233/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 555.3306 - val_loss: 558.0416\n",
      "Epoch 234/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 553.9732 - val_loss: 556.8028\n",
      "Epoch 235/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 552.6870 - val_loss: 555.6289\n",
      "Epoch 236/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 551.4701 - val_loss: 554.5343\n",
      "Epoch 237/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 550.3300 - val_loss: 553.4921\n",
      "Epoch 238/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 549.2517 - val_loss: 552.5218\n",
      "Epoch 239/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 548.2383 - val_loss: 551.6234\n",
      "Epoch 240/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 547.2920 - val_loss: 550.7713\n",
      "Epoch 241/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 546.3975 - val_loss: 549.9883\n",
      "Epoch 242/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 545.5652 - val_loss: 549.2525\n",
      "Epoch 243/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 544.7851 - val_loss: 548.5651\n",
      "Epoch 244/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 544.0522 - val_loss: 547.9409\n",
      "Epoch 245/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 543.3780 - val_loss: 547.3387\n",
      "Epoch 246/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.7392 - val_loss: 546.7974\n",
      "Epoch 247/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.1567 - val_loss: 546.2754\n",
      "Epoch 248/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.6061 - val_loss: 545.8085\n",
      "Epoch 249/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 541.0963 - val_loss: 545.3862\n",
      "Epoch 250/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.6299 - val_loss: 544.9888\n",
      "Epoch 251/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.1923 - val_loss: 544.6338\n",
      "Epoch 252/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.7971 - val_loss: 544.2921\n",
      "Epoch 253/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.4218 - val_loss: 543.9942\n",
      "Epoch 254/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.0841 - val_loss: 543.7136\n",
      "Epoch 255/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.7718 - val_loss: 543.4558\n",
      "Epoch 256/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.4818 - val_loss: 543.2297\n",
      "Epoch 257/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.2162 - val_loss: 543.0317\n",
      "Epoch 258/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.9805 - val_loss: 542.8390\n",
      "Epoch 259/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.7575 - val_loss: 542.6758\n",
      "Epoch 260/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.5611 - val_loss: 542.5195\n",
      "Epoch 261/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.3751 - val_loss: 542.3915\n",
      "Epoch 262/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.2127 - val_loss: 542.2681\n",
      "Epoch 263/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.0644 - val_loss: 542.1557\n",
      "Epoch 264/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.9298 - val_loss: 542.0584\n",
      "Epoch 265/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8028 - val_loss: 541.9859\n",
      "Epoch 266/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.7000 - val_loss: 541.9061\n",
      "Epoch 267/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.5956 - val_loss: 541.8453\n",
      "Epoch 268/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.5080 - val_loss: 541.7897\n",
      "Epoch 269/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.4280 - val_loss: 541.7425\n",
      "Epoch 270/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.3571 - val_loss: 541.7012\n",
      "Epoch 271/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.2964 - val_loss: 541.6617\n",
      "Epoch 272/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.2364 - val_loss: 541.6353\n",
      "Epoch 273/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.1877 - val_loss: 541.6098\n",
      "Epoch 274/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.1464 - val_loss: 541.5861\n",
      "Epoch 275/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.1032 - val_loss: 541.5711\n",
      "Epoch 276/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.0719 - val_loss: 541.5566\n",
      "Epoch 277/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.0412 - val_loss: 541.5474\n",
      "Epoch 278/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.0145 - val_loss: 541.5388\n",
      "Epoch 279/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 535.9915 - val_loss: 541.5328\n",
      "Epoch 280/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 535.9707 - val_loss: 541.5285\n",
      "Epoch 281/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 535.9526 - val_loss: 541.5255\n",
      "Epoch 282/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 535.9384 - val_loss: 541.5241\n",
      "Epoch 283/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 535.9249 - val_loss: 541.5235\n",
      "Epoch 284/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 535.9125 - val_loss: 541.5239\n",
      "Epoch 285/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 535.9019 - val_loss: 541.5253\n",
      "Epoch 286/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 535.8935 - val_loss: 541.5275\n",
      "Epoch 287/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 535.8854 - val_loss: 541.5294\n",
      "Epoch 288/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 535.8806 - val_loss: 541.5329\n",
      "Epoch 289/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 535.8737 - val_loss: 541.5334\n",
      "Epoch 00289: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(13, return_sequences=True, input_shape=(120, 13))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 120, 13)           1404      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 120, 1)            14        \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 120, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,418\n",
      "Trainable params: 1,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4466 samples, validate on 1915 samples\n",
      "Epoch 1/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 9301.0931 - val_loss: 9228.0435\n",
      "Epoch 2/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 9046.0893 - val_loss: 8878.6831\n",
      "Epoch 3/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8739.9598 - val_loss: 8597.4508\n",
      "Epoch 4/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8478.8812 - val_loss: 8385.4733\n",
      "Epoch 5/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8303.4787 - val_loss: 8239.9677\n",
      "Epoch 6/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8175.9569 - val_loss: 8121.1556\n",
      "Epoch 7/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8058.3320 - val_loss: 8006.1780\n",
      "Epoch 8/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7950.2993 - val_loss: 7904.1680\n",
      "Epoch 9/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7850.6930 - val_loss: 7806.6997\n",
      "Epoch 10/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7755.0251 - val_loss: 7712.5894\n",
      "Epoch 11/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7662.2599 - val_loss: 7621.0809\n",
      "Epoch 12/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7571.8741 - val_loss: 7531.5951\n",
      "Epoch 13/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7483.4057 - val_loss: 7443.9820\n",
      "Epoch 14/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7396.6531 - val_loss: 7357.9752\n",
      "Epoch 15/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7311.3922 - val_loss: 7273.4327\n",
      "Epoch 16/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7227.4992 - val_loss: 7190.1295\n",
      "Epoch 17/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7144.8718 - val_loss: 7107.9229\n",
      "Epoch 18/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7063.3430 - val_loss: 7026.9887\n",
      "Epoch 19/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6982.9580 - val_loss: 6947.0568\n",
      "Epoch 20/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6903.5805 - val_loss: 6868.0998\n",
      "Epoch 21/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6825.1709 - val_loss: 6790.0716\n",
      "Epoch 22/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6747.6900 - val_loss: 6712.9484\n",
      "Epoch 23/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6671.0790 - val_loss: 6636.8162\n",
      "Epoch 24/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6595.4036 - val_loss: 6561.4255\n",
      "Epoch 25/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6520.5019 - val_loss: 6486.9846\n",
      "Epoch 26/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6446.4841 - val_loss: 6413.2496\n",
      "Epoch 27/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6373.2427 - val_loss: 6340.3030\n",
      "Epoch 28/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6300.7532 - val_loss: 6268.2024\n",
      "Epoch 29/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6229.0622 - val_loss: 6196.7804\n",
      "Epoch 30/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6158.0649 - val_loss: 6126.1524\n",
      "Epoch 31/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6087.8179 - val_loss: 6056.1604\n",
      "Epoch 32/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6018.2547 - val_loss: 5986.8224\n",
      "Epoch 33/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5949.3544 - val_loss: 5918.1835\n",
      "Epoch 34/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5881.1031 - val_loss: 5850.2444\n",
      "Epoch 35/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5813.5437 - val_loss: 5782.8783\n",
      "Epoch 36/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5746.5772 - val_loss: 5716.2632\n",
      "Epoch 37/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5680.2946 - val_loss: 5650.2253\n",
      "Epoch 38/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5614.6125 - val_loss: 5584.8565\n",
      "Epoch 39/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5549.6004 - val_loss: 5519.9908\n",
      "Epoch 40/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5485.1416 - val_loss: 5455.8591\n",
      "Epoch 41/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5421.3324 - val_loss: 5392.3564\n",
      "Epoch 42/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5358.1696 - val_loss: 5329.3617\n",
      "Epoch 43/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5295.5812 - val_loss: 5267.0004\n",
      "Epoch 44/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5233.6037 - val_loss: 5205.2494\n",
      "Epoch 45/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5172.2096 - val_loss: 5144.1156\n",
      "Epoch 46/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5111.4185 - val_loss: 5083.5542\n",
      "Epoch 47/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5051.1942 - val_loss: 5023.5925\n",
      "Epoch 48/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4991.5662 - val_loss: 4964.1324\n",
      "Epoch 49/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4932.4375 - val_loss: 4905.3848\n",
      "Epoch 50/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4873.9519 - val_loss: 4847.0195\n",
      "Epoch 51/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4815.9505 - val_loss: 4789.2605\n",
      "Epoch 52/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4758.5016 - val_loss: 4732.0497\n",
      "Epoch 53/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4701.6172 - val_loss: 4675.3005\n",
      "Epoch 54/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4645.2189 - val_loss: 4619.1409\n",
      "Epoch 55/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4589.3610 - val_loss: 4563.5121\n",
      "Epoch 56/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4534.0383 - val_loss: 4508.3637\n",
      "Epoch 57/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4479.2178 - val_loss: 4453.7448\n",
      "Epoch 58/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4424.9029 - val_loss: 4399.6659\n",
      "Epoch 59/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4371.1208 - val_loss: 4346.0180\n",
      "Epoch 60/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4317.8100 - val_loss: 4292.9006\n",
      "Epoch 61/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4264.9843 - val_loss: 4240.3271\n",
      "Epoch 62/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4212.6825 - val_loss: 4188.2008\n",
      "Epoch 63/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4160.8484 - val_loss: 4136.5900\n",
      "Epoch 64/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4109.5464 - val_loss: 4085.3669\n",
      "Epoch 65/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4058.6546 - val_loss: 4034.7676\n",
      "Epoch 66/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4008.3228 - val_loss: 3984.5187\n",
      "Epoch 67/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3958.4020 - val_loss: 3934.8631\n",
      "Epoch 68/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3908.9873 - val_loss: 3885.6553\n",
      "Epoch 69/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3860.0571 - val_loss: 3836.8401\n",
      "Epoch 70/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3811.5596 - val_loss: 3788.5219\n",
      "Epoch 71/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3763.5452 - val_loss: 3740.6279\n",
      "Epoch 72/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3715.9684 - val_loss: 3693.2412\n",
      "Epoch 73/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3668.8467 - val_loss: 3646.3718\n",
      "Epoch 74/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3622.2213 - val_loss: 3599.8573\n",
      "Epoch 75/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3575.9967 - val_loss: 3553.8613\n",
      "Epoch 76/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3530.2583 - val_loss: 3508.2476\n",
      "Epoch 77/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3484.9417 - val_loss: 3463.1130\n",
      "Epoch 78/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3440.0795 - val_loss: 3418.4223\n",
      "Epoch 79/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3395.6652 - val_loss: 3374.1491\n",
      "Epoch 80/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3351.6632 - val_loss: 3330.3701\n",
      "Epoch 81/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3308.1481 - val_loss: 3286.9208\n",
      "Epoch 82/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3265.0069 - val_loss: 3243.9942\n",
      "Epoch 83/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3222.3051 - val_loss: 3201.5417\n",
      "Epoch 84/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3180.0838 - val_loss: 3159.3721\n",
      "Epoch 85/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3138.2122 - val_loss: 3117.7736\n",
      "Epoch 86/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3096.8370 - val_loss: 3076.5003\n",
      "Epoch 87/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3055.8704 - val_loss: 3035.6369\n",
      "Epoch 88/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3015.2969 - val_loss: 2995.2786\n",
      "Epoch 89/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2975.1825 - val_loss: 2955.2894\n",
      "Epoch 90/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2935.4751 - val_loss: 2915.7208\n",
      "Epoch 91/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2896.1704 - val_loss: 2876.6025\n",
      "Epoch 92/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2857.2707 - val_loss: 2837.9312\n",
      "Epoch 93/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2818.8115 - val_loss: 2799.5909\n",
      "Epoch 94/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2780.7423 - val_loss: 2761.6536\n",
      "Epoch 95/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2743.0725 - val_loss: 2724.1577\n",
      "Epoch 96/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2705.8371 - val_loss: 2687.0159\n",
      "Epoch 97/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2668.9792 - val_loss: 2650.2984\n",
      "Epoch 98/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2632.5140 - val_loss: 2614.0272\n",
      "Epoch 99/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2596.4730 - val_loss: 2578.1357\n",
      "Epoch 100/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2560.8350 - val_loss: 2542.5938\n",
      "Epoch 101/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2525.5610 - val_loss: 2507.4967\n",
      "Epoch 102/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2490.6775 - val_loss: 2472.8437\n",
      "Epoch 103/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2456.2390 - val_loss: 2438.4492\n",
      "Epoch 104/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2422.1316 - val_loss: 2404.5210\n",
      "Epoch 105/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2388.4632 - val_loss: 2370.8895\n",
      "Epoch 106/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2355.1305 - val_loss: 2337.7369\n",
      "Epoch 107/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2322.1887 - val_loss: 2305.0197\n",
      "Epoch 108/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2289.6435 - val_loss: 2272.6641\n",
      "Epoch 109/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2257.4967 - val_loss: 2240.5879\n",
      "Epoch 110/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2225.7214 - val_loss: 2208.8484\n",
      "Epoch 111/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2194.2812 - val_loss: 2177.5910\n",
      "Epoch 112/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2163.2290 - val_loss: 2146.7521\n",
      "Epoch 113/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2132.5812 - val_loss: 2116.1958\n",
      "Epoch 114/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2102.2701 - val_loss: 2086.0394\n",
      "Epoch 115/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2072.3515 - val_loss: 2056.2089\n",
      "Epoch 116/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2042.7556 - val_loss: 2026.8337\n",
      "Epoch 117/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2013.5779 - val_loss: 1997.7214\n",
      "Epoch 118/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1984.7150 - val_loss: 1969.0437\n",
      "Epoch 119/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1956.2328 - val_loss: 1940.7197\n",
      "Epoch 120/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1928.1135 - val_loss: 1912.7178\n",
      "Epoch 121/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1900.3524 - val_loss: 1885.0345\n",
      "Epoch 122/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1872.9234 - val_loss: 1857.7495\n",
      "Epoch 123/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1845.8510 - val_loss: 1830.8463\n",
      "Epoch 124/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1819.1519 - val_loss: 1804.2324\n",
      "Epoch 125/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1792.7826 - val_loss: 1777.9864\n",
      "Epoch 126/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1766.7628 - val_loss: 1752.1002\n",
      "Epoch 127/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1741.0944 - val_loss: 1726.5413\n",
      "Epoch 128/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1715.7528 - val_loss: 1701.3672\n",
      "Epoch 129/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1690.7674 - val_loss: 1676.5190\n",
      "Epoch 130/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1666.1357 - val_loss: 1651.9502\n",
      "Epoch 131/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1641.8124 - val_loss: 1627.7719\n",
      "Epoch 132/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1617.8474 - val_loss: 1603.9000\n",
      "Epoch 133/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1594.1877 - val_loss: 1580.4235\n",
      "Epoch 134/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1570.9015 - val_loss: 1557.2026\n",
      "Epoch 135/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1547.9121 - val_loss: 1534.3509\n",
      "Epoch 136/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1525.2671 - val_loss: 1511.8098\n",
      "Epoch 137/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1502.9375 - val_loss: 1489.6364\n",
      "Epoch 138/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1480.9452 - val_loss: 1467.7766\n",
      "Epoch 139/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1459.2889 - val_loss: 1446.1657\n",
      "Epoch 140/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1437.9184 - val_loss: 1424.9393\n",
      "Epoch 141/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1416.9060 - val_loss: 1403.9794\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1396.1642 - val_loss: 1383.4337\n",
      "Epoch 143/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1375.7932 - val_loss: 1363.1204\n",
      "Epoch 144/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1355.6745 - val_loss: 1343.2349\n",
      "Epoch 145/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1335.9529 - val_loss: 1323.4837\n",
      "Epoch 146/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1316.4500 - val_loss: 1304.1842\n",
      "Epoch 147/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1297.3366 - val_loss: 1285.0625\n",
      "Epoch 148/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1278.4646 - val_loss: 1266.3424\n",
      "Epoch 149/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1259.9257 - val_loss: 1247.9281\n",
      "Epoch 150/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1241.6917 - val_loss: 1229.8131\n",
      "Epoch 151/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1223.7763 - val_loss: 1211.9259\n",
      "Epoch 152/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1206.1242 - val_loss: 1194.4150\n",
      "Epoch 153/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1188.7784 - val_loss: 1177.2231\n",
      "Epoch 154/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1171.7501 - val_loss: 1160.2621\n",
      "Epoch 155/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1154.9931 - val_loss: 1143.6092\n",
      "Epoch 156/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1138.5261 - val_loss: 1127.2671\n",
      "Epoch 157/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1122.3629 - val_loss: 1111.1981\n",
      "Epoch 158/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1106.4791 - val_loss: 1095.4173\n",
      "Epoch 159/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1090.8913 - val_loss: 1079.8843\n",
      "Epoch 160/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1075.5639 - val_loss: 1064.6766\n",
      "Epoch 161/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1060.5412 - val_loss: 1049.7169\n",
      "Epoch 162/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1045.7778 - val_loss: 1035.0702\n",
      "Epoch 163/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1031.2967 - val_loss: 1020.7148\n",
      "Epoch 164/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1017.1099 - val_loss: 1006.5715\n",
      "Epoch 165/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1003.1644 - val_loss: 992.7598\n",
      "Epoch 166/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 989.5051 - val_loss: 979.2187\n",
      "Epoch 167/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 976.1268 - val_loss: 965.9061\n",
      "Epoch 168/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 963.0217 - val_loss: 952.7987\n",
      "Epoch 169/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 950.1189 - val_loss: 940.1199\n",
      "Epoch 170/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 937.5578 - val_loss: 927.5798\n",
      "Epoch 171/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 925.2150 - val_loss: 915.3224\n",
      "Epoch 172/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 913.1195 - val_loss: 903.3759\n",
      "Epoch 173/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 901.3065 - val_loss: 891.6320\n",
      "Epoch 174/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 889.7485 - val_loss: 880.1007\n",
      "Epoch 175/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 878.4082 - val_loss: 868.8880\n",
      "Epoch 176/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 867.3640 - val_loss: 857.8424\n",
      "Epoch 177/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 856.5004 - val_loss: 847.1747\n",
      "Epoch 178/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 845.9346 - val_loss: 836.6818\n",
      "Epoch 179/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 835.6003 - val_loss: 826.4069\n",
      "Epoch 180/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 825.5006 - val_loss: 816.3496\n",
      "Epoch 181/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 815.6290 - val_loss: 806.5648\n",
      "Epoch 182/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 805.9814 - val_loss: 797.0629\n",
      "Epoch 183/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 796.5931 - val_loss: 787.7357\n",
      "Epoch 184/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 787.4203 - val_loss: 778.6301\n",
      "Epoch 185/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 778.4862 - val_loss: 769.7087\n",
      "Epoch 186/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 769.7314 - val_loss: 761.1201\n",
      "Epoch 187/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 761.2524 - val_loss: 752.6609\n",
      "Epoch 188/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 752.9666 - val_loss: 744.4281\n",
      "Epoch 189/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 744.8939 - val_loss: 736.4358\n",
      "Epoch 190/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 737.0315 - val_loss: 728.6865\n",
      "Epoch 191/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 729.4051 - val_loss: 721.0879\n",
      "Epoch 192/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 721.9602 - val_loss: 713.7203\n",
      "Epoch 193/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 714.7260 - val_loss: 706.5760\n",
      "Epoch 194/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 707.7210 - val_loss: 699.5579\n",
      "Epoch 195/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 700.8748 - val_loss: 692.8017\n",
      "Epoch 196/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 694.2323 - val_loss: 686.2787\n",
      "Epoch 197/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 687.8052 - val_loss: 679.9045\n",
      "Epoch 198/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 681.5640 - val_loss: 673.6895\n",
      "Epoch 199/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 675.4958 - val_loss: 667.6978\n",
      "Epoch 200/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 669.6215 - val_loss: 661.8960\n",
      "Epoch 201/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 663.9381 - val_loss: 656.2520\n",
      "Epoch 202/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 658.4176 - val_loss: 650.8214\n",
      "Epoch 203/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 653.0951 - val_loss: 645.5111\n",
      "Epoch 204/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 647.9193 - val_loss: 640.4135\n",
      "Epoch 205/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 642.9361 - val_loss: 635.4490\n",
      "Epoch 206/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 638.0980 - val_loss: 630.7004\n",
      "Epoch 207/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 633.4413 - val_loss: 626.0993\n",
      "Epoch 208/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 628.9597 - val_loss: 621.5974\n",
      "Epoch 209/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 624.5903 - val_loss: 617.3522\n",
      "Epoch 210/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 620.4379 - val_loss: 613.1567\n",
      "Epoch 211/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 616.3706 - val_loss: 609.2317\n",
      "Epoch 212/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 612.5048 - val_loss: 605.3737\n",
      "Epoch 213/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 608.7615 - val_loss: 601.6665\n",
      "Epoch 214/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 605.1659 - val_loss: 598.0969\n",
      "Epoch 215/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 601.6974 - val_loss: 594.7113\n",
      "Epoch 216/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 598.3905 - val_loss: 591.4094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 595.2025 - val_loss: 588.2435\n",
      "Epoch 218/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 592.1410 - val_loss: 585.2304\n",
      "Epoch 219/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 589.2055 - val_loss: 582.3651\n",
      "Epoch 220/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 586.4119 - val_loss: 579.5652\n",
      "Epoch 221/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 583.7179 - val_loss: 576.9143\n",
      "Epoch 222/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 581.1498 - val_loss: 574.3749\n",
      "Epoch 223/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 578.6959 - val_loss: 571.9499\n",
      "Epoch 224/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 576.3563 - val_loss: 569.6286\n",
      "Epoch 225/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 574.1145 - val_loss: 567.4394\n",
      "Epoch 226/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 571.9926 - val_loss: 565.3304\n",
      "Epoch 227/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 569.9601 - val_loss: 563.3345\n",
      "Epoch 228/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 568.0250 - val_loss: 561.4459\n",
      "Epoch 229/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 566.1950 - val_loss: 559.6285\n",
      "Epoch 230/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 564.4509 - val_loss: 557.9044\n",
      "Epoch 231/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 562.8019 - val_loss: 556.2475\n",
      "Epoch 232/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 561.2227 - val_loss: 554.7203\n",
      "Epoch 233/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 559.7476 - val_loss: 553.2415\n",
      "Epoch 234/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 558.3493 - val_loss: 551.8310\n",
      "Epoch 235/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 557.0006 - val_loss: 550.5815\n",
      "Epoch 236/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 555.7739 - val_loss: 549.3067\n",
      "Epoch 237/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 554.5806 - val_loss: 548.1512\n",
      "Epoch 238/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 553.4665 - val_loss: 547.0665\n",
      "Epoch 239/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 552.4277 - val_loss: 546.0209\n",
      "Epoch 240/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 551.4480 - val_loss: 545.0310\n",
      "Epoch 241/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 550.5195 - val_loss: 544.1268\n",
      "Epoch 242/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 549.6555 - val_loss: 543.2820\n",
      "Epoch 243/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 548.8473 - val_loss: 542.4881\n",
      "Epoch 244/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 548.0908 - val_loss: 541.7459\n",
      "Epoch 245/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 547.3954 - val_loss: 541.0211\n",
      "Epoch 246/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 546.7238 - val_loss: 540.3825\n",
      "Epoch 247/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 546.1132 - val_loss: 539.7830\n",
      "Epoch 248/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 545.5454 - val_loss: 539.2183\n",
      "Epoch 249/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 545.0146 - val_loss: 538.7003\n",
      "Epoch 250/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 544.5279 - val_loss: 538.2066\n",
      "Epoch 251/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 544.0686 - val_loss: 537.7694\n",
      "Epoch 252/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 543.6542 - val_loss: 537.3415\n",
      "Epoch 253/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 543.2647 - val_loss: 536.9574\n",
      "Epoch 254/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 542.9081 - val_loss: 536.6012\n",
      "Epoch 255/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 542.5794 - val_loss: 536.2757\n",
      "Epoch 256/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 542.2784 - val_loss: 535.9749\n",
      "Epoch 257/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.0020 - val_loss: 535.6989\n",
      "Epoch 258/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 541.7496 - val_loss: 535.4441\n",
      "Epoch 259/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.5220 - val_loss: 535.2027\n",
      "Epoch 260/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.3082 - val_loss: 534.9945\n",
      "Epoch 261/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.1156 - val_loss: 534.8111\n",
      "Epoch 262/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.9455 - val_loss: 534.6295\n",
      "Epoch 263/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.7856 - val_loss: 534.4725\n",
      "Epoch 264/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.6433 - val_loss: 534.3281\n",
      "Epoch 265/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.5149 - val_loss: 534.1958\n",
      "Epoch 266/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.3991 - val_loss: 534.0763\n",
      "Epoch 267/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.2926 - val_loss: 533.9749\n",
      "Epoch 268/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.2014 - val_loss: 533.8734\n",
      "Epoch 269/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.1157 - val_loss: 533.7883\n",
      "Epoch 270/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.0396 - val_loss: 533.7140\n",
      "Epoch 271/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.9731 - val_loss: 533.6448\n",
      "Epoch 272/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.9161 - val_loss: 533.5768\n",
      "Epoch 273/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.8589 - val_loss: 533.5228\n",
      "Epoch 274/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.8138 - val_loss: 533.4722\n",
      "Epoch 275/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.7728 - val_loss: 533.4232\n",
      "Epoch 276/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.7351 - val_loss: 533.3833\n",
      "Epoch 277/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.7009 - val_loss: 533.3528\n",
      "Epoch 278/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6742 - val_loss: 533.3207\n",
      "Epoch 279/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6478 - val_loss: 533.2963\n",
      "Epoch 280/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6267 - val_loss: 533.2717\n",
      "Epoch 281/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6099 - val_loss: 533.2459\n",
      "Epoch 282/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.5903 - val_loss: 533.2283\n",
      "Epoch 283/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.5754 - val_loss: 533.2170\n",
      "Epoch 284/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.5638 - val_loss: 533.1986\n",
      "Epoch 285/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5547 - val_loss: 533.1834\n",
      "Epoch 286/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.5435 - val_loss: 533.1724\n",
      "Epoch 287/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5343 - val_loss: 533.1645\n",
      "Epoch 288/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.5280 - val_loss: 533.1546\n",
      "Epoch 289/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5237 - val_loss: 533.1449\n",
      "Epoch 290/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.5158 - val_loss: 533.1402\n",
      "Epoch 291/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5124 - val_loss: 533.1340\n",
      "Epoch 292/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5074 - val_loss: 533.1295\n",
      "Epoch 293/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5052 - val_loss: 533.1261\n",
      "Epoch 294/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5011 - val_loss: 533.1209\n",
      "Epoch 295/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.4977 - val_loss: 533.1155\n",
      "Epoch 296/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.4959 - val_loss: 533.1130\n",
      "Epoch 297/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.4954 - val_loss: 533.1087\n",
      "Epoch 298/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.4925 - val_loss: 533.1070\n",
      "Epoch 299/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.4906 - val_loss: 533.1040\n",
      "Epoch 00299: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(13, return_sequences=True, input_shape=(120, 13))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 120, 13)           1404      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 120, 1)            14        \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 120, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,418\n",
      "Trainable params: 1,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4466 samples, validate on 1915 samples\n",
      "Epoch 1/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 9182.7048 - val_loss: 9032.7123\n",
      "Epoch 2/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8823.0292 - val_loss: 8621.7478\n",
      "Epoch 3/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8472.4530 - val_loss: 8308.4076\n",
      "Epoch 4/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8202.3676 - val_loss: 8108.2042\n",
      "Epoch 5/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8048.1330 - val_loss: 7986.1241\n",
      "Epoch 6/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7939.8446 - val_loss: 7883.9770\n",
      "Epoch 7/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7840.2783 - val_loss: 7786.9092\n",
      "Epoch 8/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7744.8771 - val_loss: 7693.2804\n",
      "Epoch 9/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7652.5575 - val_loss: 7602.2031\n",
      "Epoch 10/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7562.6009 - val_loss: 7513.3002\n",
      "Epoch 11/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7474.6054 - val_loss: 7426.2227\n",
      "Epoch 12/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 7388.2666 - val_loss: 7340.7850\n",
      "Epoch 13/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7303.4387 - val_loss: 7256.6865\n",
      "Epoch 14/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7219.9511 - val_loss: 7173.8265\n",
      "Epoch 15/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7137.6563 - val_loss: 7092.2869\n",
      "Epoch 16/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7056.5629 - val_loss: 7011.7756\n",
      "Epoch 17/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6976.5255 - val_loss: 6932.2513\n",
      "Epoch 18/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6897.4735 - val_loss: 6853.6883\n",
      "Epoch 19/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6819.3457 - val_loss: 6776.0814\n",
      "Epoch 20/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6742.1146 - val_loss: 6699.3586\n",
      "Epoch 21/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6665.7685 - val_loss: 6623.3877\n",
      "Epoch 22/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6590.1869 - val_loss: 6548.3859\n",
      "Epoch 23/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6515.5182 - val_loss: 6474.0363\n",
      "Epoch 24/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6441.5925 - val_loss: 6400.5757\n",
      "Epoch 25/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6368.4798 - val_loss: 6327.8963\n",
      "Epoch 26/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6296.1207 - val_loss: 6256.0383\n",
      "Epoch 27/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6224.5374 - val_loss: 6184.8895\n",
      "Epoch 28/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6153.6715 - val_loss: 6114.4353\n",
      "Epoch 29/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6083.5459 - val_loss: 6044.5803\n",
      "Epoch 30/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6014.0274 - val_loss: 5975.5985\n",
      "Epoch 31/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5945.2782 - val_loss: 5907.1461\n",
      "Epoch 32/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5877.1328 - val_loss: 5839.3752\n",
      "Epoch 33/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5809.6216 - val_loss: 5772.2944\n",
      "Epoch 34/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5742.7870 - val_loss: 5705.7124\n",
      "Epoch 35/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5676.5161 - val_loss: 5639.8272\n",
      "Epoch 36/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5610.8934 - val_loss: 5574.5183\n",
      "Epoch 37/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5545.8651 - val_loss: 5509.8323\n",
      "Epoch 38/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5481.4325 - val_loss: 5445.7652\n",
      "Epoch 39/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5417.6132 - val_loss: 5382.2728\n",
      "Epoch 40/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5354.3841 - val_loss: 5319.3536\n",
      "Epoch 41/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5291.7098 - val_loss: 5257.1073\n",
      "Epoch 42/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5229.6716 - val_loss: 5195.3571\n",
      "Epoch 43/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5168.1964 - val_loss: 5134.1988\n",
      "Epoch 44/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5107.3097 - val_loss: 5073.6007\n",
      "Epoch 45/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5046.9771 - val_loss: 5013.6753\n",
      "Epoch 46/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4987.2750 - val_loss: 4954.2236\n",
      "Epoch 47/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4928.0937 - val_loss: 4895.4017\n",
      "Epoch 48/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4869.4970 - val_loss: 4837.1101\n",
      "Epoch 49/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4811.4594 - val_loss: 4779.3521\n",
      "Epoch 50/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4753.9392 - val_loss: 4722.2131\n",
      "Epoch 51/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4697.0013 - val_loss: 4665.5509\n",
      "Epoch 52/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4640.5674 - val_loss: 4609.4718\n",
      "Epoch 53/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4584.6868 - val_loss: 4553.8821\n",
      "Epoch 54/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4529.3272 - val_loss: 4498.7929\n",
      "Epoch 55/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4474.4929 - val_loss: 4444.1832\n",
      "Epoch 56/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4420.1277 - val_loss: 4390.2115\n",
      "Epoch 57/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4366.3123 - val_loss: 4336.7244\n",
      "Epoch 58/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4313.0077 - val_loss: 4283.6688\n",
      "Epoch 59/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4260.1692 - val_loss: 4231.1423\n",
      "Epoch 60/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4207.8473 - val_loss: 4179.0610\n",
      "Epoch 61/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 4155.9610 - val_loss: 4127.6011\n",
      "Epoch 62/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4104.6475 - val_loss: 4076.4558\n",
      "Epoch 63/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4053.7586 - val_loss: 4025.8230\n",
      "Epoch 64/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4003.3379 - val_loss: 3975.7349\n",
      "Epoch 65/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3953.4219 - val_loss: 3926.0903\n",
      "Epoch 66/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3903.9791 - val_loss: 3876.8777\n",
      "Epoch 67/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3854.9717 - val_loss: 3828.2033\n",
      "Epoch 68/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3806.4517 - val_loss: 3779.9969\n",
      "Epoch 69/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3758.4280 - val_loss: 3732.1317\n",
      "Epoch 70/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3710.8017 - val_loss: 3684.8430\n",
      "Epoch 71/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3663.6982 - val_loss: 3637.9077\n",
      "Epoch 72/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3616.9794 - val_loss: 3591.5735\n",
      "Epoch 73/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3570.7805 - val_loss: 3545.5809\n",
      "Epoch 74/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3524.9905 - val_loss: 3500.0713\n",
      "Epoch 75/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3479.6592 - val_loss: 3454.9908\n",
      "Epoch 76/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3434.7692 - val_loss: 3410.3512\n",
      "Epoch 77/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3390.3186 - val_loss: 3366.1532\n",
      "Epoch 78/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3346.3220 - val_loss: 3322.3512\n",
      "Epoch 79/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3302.7149 - val_loss: 3279.1012\n",
      "Epoch 80/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3259.5909 - val_loss: 3236.2167\n",
      "Epoch 81/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3216.8866 - val_loss: 3193.7384\n",
      "Epoch 82/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3174.5915 - val_loss: 3151.7311\n",
      "Epoch 83/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3132.7335 - val_loss: 3110.1731\n",
      "Epoch 84/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3091.3357 - val_loss: 3068.9464\n",
      "Epoch 85/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3050.3188 - val_loss: 3028.1932\n",
      "Epoch 86/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3009.7252 - val_loss: 2987.9002\n",
      "Epoch 87/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2969.6069 - val_loss: 2947.8811\n",
      "Epoch 88/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2929.8169 - val_loss: 2908.4336\n",
      "Epoch 89/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2890.5052 - val_loss: 2869.3179\n",
      "Epoch 90/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2851.5605 - val_loss: 2830.6897\n",
      "Epoch 91/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2813.0777 - val_loss: 2792.3522\n",
      "Epoch 92/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2774.9523 - val_loss: 2754.4872\n",
      "Epoch 93/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2737.2396 - val_loss: 2717.0630\n",
      "Epoch 94/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2699.9668 - val_loss: 2679.9503\n",
      "Epoch 95/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2663.0430 - val_loss: 2643.3335\n",
      "Epoch 96/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2626.5566 - val_loss: 2607.0799\n",
      "Epoch 97/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 2590.4849 - val_loss: 2571.1547\n",
      "Epoch 98/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2554.7581 - val_loss: 2535.7385\n",
      "Epoch 99/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2519.4756 - val_loss: 2500.6534\n",
      "Epoch 100/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2484.5610 - val_loss: 2465.9967\n",
      "Epoch 101/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2450.0331 - val_loss: 2431.7676\n",
      "Epoch 102/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2415.9159 - val_loss: 2397.8769\n",
      "Epoch 103/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2382.1965 - val_loss: 2364.3097\n",
      "Epoch 104/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2348.8329 - val_loss: 2331.1832\n",
      "Epoch 105/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2315.8720 - val_loss: 2298.4405\n",
      "Epoch 106/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2283.2894 - val_loss: 2266.0951\n",
      "Epoch 107/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2251.0960 - val_loss: 2234.1271\n",
      "Epoch 108/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2219.2686 - val_loss: 2202.5724\n",
      "Epoch 109/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2187.8473 - val_loss: 2171.3331\n",
      "Epoch 110/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2156.7686 - val_loss: 2140.5256\n",
      "Epoch 111/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2126.0992 - val_loss: 2110.0221\n",
      "Epoch 112/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2095.7776 - val_loss: 2079.9042\n",
      "Epoch 113/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2065.8271 - val_loss: 2050.1670\n",
      "Epoch 114/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2036.2510 - val_loss: 2020.8143\n",
      "Epoch 115/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2007.0507 - val_loss: 1991.8078\n",
      "Epoch 116/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1978.1979 - val_loss: 1963.2180\n",
      "Epoch 117/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1949.7310 - val_loss: 1934.9424\n",
      "Epoch 118/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1921.5861 - val_loss: 1907.1102\n",
      "Epoch 119/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1893.8428 - val_loss: 1879.5565\n",
      "Epoch 120/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1866.4581 - val_loss: 1852.2881\n",
      "Epoch 121/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1839.3913 - val_loss: 1825.4545\n",
      "Epoch 122/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1812.6888 - val_loss: 1798.9977\n",
      "Epoch 123/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1786.3556 - val_loss: 1772.8592\n",
      "Epoch 124/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1760.3636 - val_loss: 1747.0551\n",
      "Epoch 125/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1734.7190 - val_loss: 1721.5885\n",
      "Epoch 126/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1709.3948 - val_loss: 1696.5325\n",
      "Epoch 127/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1684.4661 - val_loss: 1671.6989\n",
      "Epoch 128/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1659.8076 - val_loss: 1647.3280\n",
      "Epoch 129/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1635.5326 - val_loss: 1623.2739\n",
      "Epoch 130/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1611.6041 - val_loss: 1599.4918\n",
      "Epoch 131/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1587.9828 - val_loss: 1576.0887\n",
      "Epoch 132/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1564.6918 - val_loss: 1553.0548\n",
      "Epoch 133/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1541.7660 - val_loss: 1530.2713\n",
      "Epoch 134/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1519.1432 - val_loss: 1507.8376\n",
      "Epoch 135/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1496.8618 - val_loss: 1485.7206\n",
      "Epoch 136/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1474.8898 - val_loss: 1463.9597\n",
      "Epoch 137/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1453.2406 - val_loss: 1442.5506\n",
      "Epoch 138/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1431.9502 - val_loss: 1421.3655\n",
      "Epoch 139/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1410.9364 - val_loss: 1400.5860\n",
      "Epoch 140/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1390.2525 - val_loss: 1380.1413\n",
      "Epoch 141/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1369.9207 - val_loss: 1359.9117\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1349.8465 - val_loss: 1340.0860\n",
      "Epoch 143/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1330.1087 - val_loss: 1320.5831\n",
      "Epoch 144/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1310.6988 - val_loss: 1301.3398\n",
      "Epoch 145/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1291.5954 - val_loss: 1282.3689\n",
      "Epoch 146/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1272.7747 - val_loss: 1263.7430\n",
      "Epoch 147/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1254.2554 - val_loss: 1245.4762\n",
      "Epoch 148/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1236.0872 - val_loss: 1227.3966\n",
      "Epoch 149/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1218.1648 - val_loss: 1209.7049\n",
      "Epoch 150/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1200.5922 - val_loss: 1192.2378\n",
      "Epoch 151/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1183.2714 - val_loss: 1175.1435\n",
      "Epoch 152/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1166.2664 - val_loss: 1158.3390\n",
      "Epoch 153/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1149.5723 - val_loss: 1141.7649\n",
      "Epoch 154/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1133.1401 - val_loss: 1125.5226\n",
      "Epoch 155/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1117.0021 - val_loss: 1109.5976\n",
      "Epoch 156/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1101.1645 - val_loss: 1093.9329\n",
      "Epoch 157/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1085.6122 - val_loss: 1078.5276\n",
      "Epoch 158/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1070.3226 - val_loss: 1063.4583\n",
      "Epoch 159/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1055.3382 - val_loss: 1048.6315\n",
      "Epoch 160/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1040.6429 - val_loss: 1034.0206\n",
      "Epoch 161/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1026.1923 - val_loss: 1019.7480\n",
      "Epoch 162/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1012.0210 - val_loss: 1005.7847\n",
      "Epoch 163/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 998.1616 - val_loss: 992.0007\n",
      "Epoch 164/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 984.5203 - val_loss: 978.5759\n",
      "Epoch 165/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 971.1837 - val_loss: 965.3841\n",
      "Epoch 166/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 958.0890 - val_loss: 952.5082\n",
      "Epoch 167/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 945.2931 - val_loss: 939.8271\n",
      "Epoch 168/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 932.7431 - val_loss: 927.3962\n",
      "Epoch 169/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 920.4347 - val_loss: 915.2805\n",
      "Epoch 170/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 908.3809 - val_loss: 903.4684\n",
      "Epoch 171/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 896.6172 - val_loss: 891.8222\n",
      "Epoch 172/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 885.0764 - val_loss: 880.4417\n",
      "Epoch 173/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 873.8043 - val_loss: 869.2784\n",
      "Epoch 174/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 862.7599 - val_loss: 858.4012\n",
      "Epoch 175/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 851.9702 - val_loss: 847.7703\n",
      "Epoch 176/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 841.4315 - val_loss: 837.3541\n",
      "Epoch 177/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 831.1046 - val_loss: 827.2552\n",
      "Epoch 178/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 821.0780 - val_loss: 817.2591\n",
      "Epoch 179/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 811.2340 - val_loss: 807.5665\n",
      "Epoch 180/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 801.6239 - val_loss: 798.1623\n",
      "Epoch 181/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 792.2795 - val_loss: 788.9238\n",
      "Epoch 182/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 783.1345 - val_loss: 779.9469\n",
      "Epoch 183/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 774.2342 - val_loss: 771.1563\n",
      "Epoch 184/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 765.5474 - val_loss: 762.5942\n",
      "Epoch 185/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 757.0781 - val_loss: 754.2736\n",
      "Epoch 186/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 748.8217 - val_loss: 746.1981\n",
      "Epoch 187/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 740.7949 - val_loss: 738.3128\n",
      "Epoch 188/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 732.9942 - val_loss: 730.5683\n",
      "Epoch 189/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 725.3685 - val_loss: 723.0924\n",
      "Epoch 190/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 717.9679 - val_loss: 715.8211\n",
      "Epoch 191/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 710.7729 - val_loss: 708.7464\n",
      "Epoch 192/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 703.7773 - val_loss: 701.8773\n",
      "Epoch 193/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 696.9945 - val_loss: 695.1713\n",
      "Epoch 194/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 690.3762 - val_loss: 688.7328\n",
      "Epoch 195/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 683.9863 - val_loss: 682.4304\n",
      "Epoch 196/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 677.7844 - val_loss: 676.2818\n",
      "Epoch 197/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 671.7280 - val_loss: 670.4162\n",
      "Epoch 198/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 665.8973 - val_loss: 664.6988\n",
      "Epoch 199/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 660.2322 - val_loss: 659.1702\n",
      "Epoch 200/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 654.7642 - val_loss: 653.7694\n",
      "Epoch 201/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 649.4507 - val_loss: 648.5747\n",
      "Epoch 202/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 644.3150 - val_loss: 643.5593\n",
      "Epoch 203/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 639.3612 - val_loss: 638.6903\n",
      "Epoch 204/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 634.5559 - val_loss: 634.0173\n",
      "Epoch 205/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 629.9259 - val_loss: 629.4959\n",
      "Epoch 206/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 625.4648 - val_loss: 625.0904\n",
      "Epoch 207/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 621.1452 - val_loss: 620.8681\n",
      "Epoch 208/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 616.9816 - val_loss: 616.8139\n",
      "Epoch 209/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 612.9781 - val_loss: 612.9035\n",
      "Epoch 210/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 609.1309 - val_loss: 609.1106\n",
      "Epoch 211/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 605.3982 - val_loss: 605.5338\n",
      "Epoch 212/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 601.8451 - val_loss: 602.0362\n",
      "Epoch 213/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 598.4108 - val_loss: 598.6841\n",
      "Epoch 214/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 595.1108 - val_loss: 595.4797\n",
      "Epoch 215/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 591.9501 - val_loss: 592.3979\n",
      "Epoch 216/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 588.9199 - val_loss: 589.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 586.0044 - val_loss: 586.6125\n",
      "Epoch 218/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 583.2201 - val_loss: 583.9161\n",
      "Epoch 219/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 580.5586 - val_loss: 581.3251\n",
      "Epoch 220/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 578.0089 - val_loss: 578.8504\n",
      "Epoch 221/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 575.5782 - val_loss: 576.4753\n",
      "Epoch 222/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 573.2496 - val_loss: 574.2268\n",
      "Epoch 223/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 571.0303 - val_loss: 572.0909\n",
      "Epoch 224/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 568.9205 - val_loss: 570.0442\n",
      "Epoch 225/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 566.9119 - val_loss: 568.0926\n",
      "Epoch 226/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 564.9965 - val_loss: 566.2456\n",
      "Epoch 227/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 563.1793 - val_loss: 564.4886\n",
      "Epoch 228/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 561.4480 - val_loss: 562.8354\n",
      "Epoch 229/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 559.8249 - val_loss: 561.2211\n",
      "Epoch 230/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 558.2562 - val_loss: 559.7480\n",
      "Epoch 231/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 556.7979 - val_loss: 558.3172\n",
      "Epoch 232/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 555.3973 - val_loss: 557.0054\n",
      "Epoch 233/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 554.0987 - val_loss: 555.7191\n",
      "Epoch 234/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 552.8587 - val_loss: 554.5151\n",
      "Epoch 235/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 551.6877 - val_loss: 553.3971\n",
      "Epoch 236/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 550.5912 - val_loss: 552.3414\n",
      "Epoch 237/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 549.5517 - val_loss: 551.3702\n",
      "Epoch 238/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 548.5816 - val_loss: 550.4574\n",
      "Epoch 239/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 547.6760 - val_loss: 549.5814\n",
      "Epoch 240/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 546.8231 - val_loss: 548.7535\n",
      "Epoch 241/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 546.0187 - val_loss: 547.9927\n",
      "Epoch 242/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 545.2684 - val_loss: 547.2957\n",
      "Epoch 243/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 544.5757 - val_loss: 546.6285\n",
      "Epoch 244/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 543.9306 - val_loss: 545.9932\n",
      "Epoch 245/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 543.3184 - val_loss: 545.4264\n",
      "Epoch 246/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.7551 - val_loss: 544.9062\n",
      "Epoch 247/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.2375 - val_loss: 544.4111\n",
      "Epoch 248/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.7576 - val_loss: 543.9389\n",
      "Epoch 249/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.3067 - val_loss: 543.5124\n",
      "Epoch 250/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.8895 - val_loss: 543.1350\n",
      "Epoch 251/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.5126 - val_loss: 542.7704\n",
      "Epoch 252/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.1585 - val_loss: 542.4490\n",
      "Epoch 253/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.8385 - val_loss: 542.1442\n",
      "Epoch 254/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.5469 - val_loss: 541.8558\n",
      "Epoch 255/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.2693 - val_loss: 541.6096\n",
      "Epoch 256/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.0245 - val_loss: 541.3785\n",
      "Epoch 257/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.8028 - val_loss: 541.1580\n",
      "Epoch 258/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 538.5844 - val_loss: 540.9935\n",
      "Epoch 259/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.4013 - val_loss: 540.8210\n",
      "Epoch 260/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.2338 - val_loss: 540.6496\n",
      "Epoch 261/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 538.0721 - val_loss: 540.5145\n",
      "Epoch 262/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.9327 - val_loss: 540.3923\n",
      "Epoch 263/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.8096 - val_loss: 540.2633\n",
      "Epoch 264/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.6903 - val_loss: 540.1633\n",
      "Epoch 265/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.5903 - val_loss: 540.0651\n",
      "Epoch 266/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.4954 - val_loss: 539.9866\n",
      "Epoch 267/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 537.4167 - val_loss: 539.9062\n",
      "Epoch 268/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.3411 - val_loss: 539.8413\n",
      "Epoch 269/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.2760 - val_loss: 539.7833\n",
      "Epoch 270/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.2183 - val_loss: 539.7299\n",
      "Epoch 271/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.1647 - val_loss: 539.6876\n",
      "Epoch 272/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 537.1195 - val_loss: 539.6470\n",
      "Epoch 273/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.0797 - val_loss: 539.6093\n",
      "Epoch 274/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 537.0423 - val_loss: 539.5823\n",
      "Epoch 275/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 537.0114 - val_loss: 539.5536\n",
      "Epoch 276/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.9827 - val_loss: 539.5312\n",
      "Epoch 277/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.9585 - val_loss: 539.5097\n",
      "Epoch 278/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.9387 - val_loss: 539.4934\n",
      "Epoch 279/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.9190 - val_loss: 539.4758\n",
      "Epoch 280/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.9032 - val_loss: 539.4668\n",
      "Epoch 281/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.8897 - val_loss: 539.4492\n",
      "Epoch 282/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.8757 - val_loss: 539.4391\n",
      "Epoch 283/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.8641 - val_loss: 539.4330\n",
      "Epoch 284/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8552 - val_loss: 539.4239\n",
      "Epoch 285/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8469 - val_loss: 539.4183\n",
      "Epoch 286/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.8420 - val_loss: 539.4119\n",
      "Epoch 287/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8341 - val_loss: 539.4098\n",
      "Epoch 288/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.8313 - val_loss: 539.4049\n",
      "Epoch 289/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8244 - val_loss: 539.4023\n",
      "Epoch 290/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8210 - val_loss: 539.3984\n",
      "Epoch 291/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 536.8167 - val_loss: 539.3959\n",
      "Epoch 292/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8143 - val_loss: 539.3950\n",
      "Epoch 293/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 536.8108 - val_loss: 539.3923\n",
      "Epoch 294/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 536.8089 - val_loss: 539.3910\n",
      "Epoch 00294: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/cynthia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(13, return_sequences=True, input_shape=(120, 13))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 120, 13)           1404      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 120, 1)            14        \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 120, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,418\n",
      "Trainable params: 1,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4466 samples, validate on 1915 samples\n",
      "Epoch 1/500\n",
      "4466/4466 [==============================] - 8s 2ms/step - loss: 9269.6459 - val_loss: 9244.2893\n",
      "Epoch 2/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 9007.1960 - val_loss: 8924.5081\n",
      "Epoch 3/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8699.9439 - val_loss: 8614.9184\n",
      "Epoch 4/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8430.8666 - val_loss: 8417.2462\n",
      "Epoch 5/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 8280.5456 - val_loss: 8294.1356\n",
      "Epoch 6/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8167.6834 - val_loss: 8185.9286\n",
      "Epoch 7/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 8063.1616 - val_loss: 8084.0389\n",
      "Epoch 8/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7964.1064 - val_loss: 7986.4710\n",
      "Epoch 9/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7868.5997 - val_loss: 7892.0092\n",
      "Epoch 10/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7775.8511 - val_loss: 7799.9140\n",
      "Epoch 11/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7685.2922 - val_loss: 7709.9707\n",
      "Epoch 12/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7596.6501 - val_loss: 7621.7366\n",
      "Epoch 13/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7509.6278 - val_loss: 7535.0006\n",
      "Epoch 14/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7424.1027 - val_loss: 7449.5700\n",
      "Epoch 15/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7339.8605 - val_loss: 7365.5438\n",
      "Epoch 16/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7256.8702 - val_loss: 7282.6958\n",
      "Epoch 17/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 7174.9978 - val_loss: 7200.9601\n",
      "Epoch 18/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7094.1908 - val_loss: 7120.1949\n",
      "Epoch 19/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 7014.3368 - val_loss: 7040.4456\n",
      "Epoch 20/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6935.4649 - val_loss: 6961.5440\n",
      "Epoch 21/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6857.4728 - val_loss: 6883.5413\n",
      "Epoch 22/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6780.3605 - val_loss: 6806.4451\n",
      "Epoch 23/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6704.1328 - val_loss: 6730.1389\n",
      "Epoch 24/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6628.6774 - val_loss: 6654.7969\n",
      "Epoch 25/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6554.1275 - val_loss: 6580.1008\n",
      "Epoch 26/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6480.2903 - val_loss: 6506.3070\n",
      "Epoch 27/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6407.2818 - val_loss: 6433.1783\n",
      "Epoch 28/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6334.9694 - val_loss: 6360.8734\n",
      "Epoch 29/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6263.4007 - val_loss: 6289.2542\n",
      "Epoch 30/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6192.5509 - val_loss: 6218.2372\n",
      "Epoch 31/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 6122.3485 - val_loss: 6147.9746\n",
      "Epoch 32/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 6052.8463 - val_loss: 6078.3567\n",
      "Epoch 33/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5983.9718 - val_loss: 6009.4507\n",
      "Epoch 34/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5915.7598 - val_loss: 5941.1600\n",
      "Epoch 35/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5848.1895 - val_loss: 5873.4253\n",
      "Epoch 36/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5781.2077 - val_loss: 5806.3774\n",
      "Epoch 37/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5714.8635 - val_loss: 5739.9279\n",
      "Epoch 38/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5649.1464 - val_loss: 5674.0759\n",
      "Epoch 39/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5584.0530 - val_loss: 5608.8499\n",
      "Epoch 40/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5519.5479 - val_loss: 5544.3018\n",
      "Epoch 41/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5455.6901 - val_loss: 5480.3003\n",
      "Epoch 42/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5392.4223 - val_loss: 5416.9268\n",
      "Epoch 43/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5329.7520 - val_loss: 5354.1547\n",
      "Epoch 44/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 5267.6392 - val_loss: 5292.0650\n",
      "Epoch 45/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5206.1920 - val_loss: 5230.3410\n",
      "Epoch 46/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5145.2329 - val_loss: 5169.3158\n",
      "Epoch 47/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5084.8822 - val_loss: 5108.8266\n",
      "Epoch 48/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 5025.0753 - val_loss: 5048.9379\n",
      "Epoch 49/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4965.8534 - val_loss: 4989.5533\n",
      "Epoch 50/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4907.1649 - val_loss: 4930.7232\n",
      "Epoch 51/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 4849.0295 - val_loss: 4872.4027\n",
      "Epoch 52/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4791.4017 - val_loss: 4814.7035\n",
      "Epoch 53/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4734.3383 - val_loss: 4757.5122\n",
      "Epoch 54/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4677.7772 - val_loss: 4700.8698\n",
      "Epoch 55/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4621.7740 - val_loss: 4644.6621\n",
      "Epoch 56/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4566.2509 - val_loss: 4589.0077\n",
      "Epoch 57/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4511.2491 - val_loss: 4533.8958\n",
      "Epoch 58/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4456.7657 - val_loss: 4479.2625\n",
      "Epoch 59/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4402.7700 - val_loss: 4425.1434\n",
      "Epoch 60/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4349.2622 - val_loss: 4371.5774\n",
      "Epoch 61/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4296.2944 - val_loss: 4318.3824\n",
      "Epoch 62/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4243.7631 - val_loss: 4265.7326\n",
      "Epoch 63/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4191.7359 - val_loss: 4213.5596\n",
      "Epoch 64/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 4140.1975 - val_loss: 4161.8271\n",
      "Epoch 65/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4089.1078 - val_loss: 4110.6363\n",
      "Epoch 66/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 4038.5370 - val_loss: 4059.8573\n",
      "Epoch 67/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3988.4167 - val_loss: 4009.5780\n",
      "Epoch 68/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3938.7301 - val_loss: 3959.9074\n",
      "Epoch 69/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3889.5946 - val_loss: 3910.5203\n",
      "Epoch 70/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3840.8627 - val_loss: 3861.6441\n",
      "Epoch 71/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3792.6056 - val_loss: 3813.2302\n",
      "Epoch 72/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3744.7942 - val_loss: 3765.3383\n",
      "Epoch 73/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3697.4810 - val_loss: 3717.8248\n",
      "Epoch 74/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3650.5955 - val_loss: 3670.7683\n",
      "Epoch 75/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3604.1642 - val_loss: 3624.1372\n",
      "Epoch 76/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3558.1308 - val_loss: 3578.0952\n",
      "Epoch 77/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3512.6300 - val_loss: 3532.3480\n",
      "Epoch 78/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3467.5142 - val_loss: 3487.1125\n",
      "Epoch 79/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3422.8735 - val_loss: 3442.2544\n",
      "Epoch 80/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3378.6490 - val_loss: 3397.8611\n",
      "Epoch 81/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3334.8462 - val_loss: 3353.9586\n",
      "Epoch 82/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3291.5003 - val_loss: 3310.4749\n",
      "Epoch 83/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3248.5949 - val_loss: 3267.3717\n",
      "Epoch 84/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3206.1020 - val_loss: 3224.7031\n",
      "Epoch 85/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3164.0129 - val_loss: 3182.5417\n",
      "Epoch 86/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3122.4085 - val_loss: 3140.7016\n",
      "Epoch 87/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 3081.1647 - val_loss: 3099.4121\n",
      "Epoch 88/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3040.4132 - val_loss: 3058.4116\n",
      "Epoch 89/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 3000.0170 - val_loss: 3017.9389\n",
      "Epoch 90/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2960.0713 - val_loss: 2977.8675\n",
      "Epoch 91/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2920.5718 - val_loss: 2938.0894\n",
      "Epoch 92/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2881.4274 - val_loss: 2898.8233\n",
      "Epoch 93/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2842.6981 - val_loss: 2860.0353\n",
      "Epoch 94/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2804.4259 - val_loss: 2821.5472\n",
      "Epoch 95/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2766.5267 - val_loss: 2783.4853\n",
      "Epoch 96/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2729.0393 - val_loss: 2745.8575\n",
      "Epoch 97/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2691.9660 - val_loss: 2708.6190\n",
      "Epoch 98/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2655.2938 - val_loss: 2671.7971\n",
      "Epoch 99/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2619.0289 - val_loss: 2635.3614\n",
      "Epoch 100/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2583.1404 - val_loss: 2599.3778\n",
      "Epoch 101/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2547.6966 - val_loss: 2563.6736\n",
      "Epoch 102/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2512.5920 - val_loss: 2528.4385\n",
      "Epoch 103/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2477.9194 - val_loss: 2493.5311\n",
      "Epoch 104/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2443.5787 - val_loss: 2459.1612\n",
      "Epoch 105/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2409.6892 - val_loss: 2425.0824\n",
      "Epoch 106/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2376.1645 - val_loss: 2391.3763\n",
      "Epoch 107/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2343.0208 - val_loss: 2358.0531\n",
      "Epoch 108/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2310.2464 - val_loss: 2325.1399\n",
      "Epoch 109/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2277.8698 - val_loss: 2292.5670\n",
      "Epoch 110/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2245.8470 - val_loss: 2260.4379\n",
      "Epoch 111/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2214.2188 - val_loss: 2228.6580\n",
      "Epoch 112/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2182.9569 - val_loss: 2197.2500\n",
      "Epoch 113/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2152.0836 - val_loss: 2166.1548\n",
      "Epoch 114/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2121.5288 - val_loss: 2135.5363\n",
      "Epoch 115/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 2091.4272 - val_loss: 2105.0959\n",
      "Epoch 116/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2061.5974 - val_loss: 2075.1799\n",
      "Epoch 117/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 2032.1859 - val_loss: 2045.5931\n",
      "Epoch 118/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 2003.0983 - val_loss: 2016.4480\n",
      "Epoch 119/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1974.4361 - val_loss: 1987.4939\n",
      "Epoch 120/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1946.0511 - val_loss: 1959.0424\n",
      "Epoch 121/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1918.0728 - val_loss: 1930.9041\n",
      "Epoch 122/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1890.4475 - val_loss: 1903.0716\n",
      "Epoch 123/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1863.1437 - val_loss: 1875.6607\n",
      "Epoch 124/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1836.2211 - val_loss: 1848.5700\n",
      "Epoch 125/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1809.6522 - val_loss: 1821.7841\n",
      "Epoch 126/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1783.4121 - val_loss: 1795.3797\n",
      "Epoch 127/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1757.5173 - val_loss: 1769.3569\n",
      "Epoch 128/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1731.9891 - val_loss: 1743.6487\n",
      "Epoch 129/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1706.7813 - val_loss: 1718.3182\n",
      "Epoch 130/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1681.9377 - val_loss: 1693.2799\n",
      "Epoch 131/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1657.4174 - val_loss: 1668.5792\n",
      "Epoch 132/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1633.2105 - val_loss: 1644.2900\n",
      "Epoch 133/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1609.3817 - val_loss: 1620.2642\n",
      "Epoch 134/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1585.8634 - val_loss: 1596.5807\n",
      "Epoch 135/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1562.6713 - val_loss: 1573.2666\n",
      "Epoch 136/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 1539.8439 - val_loss: 1550.1882\n",
      "Epoch 137/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1517.2903 - val_loss: 1527.5535\n",
      "Epoch 138/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1495.1110 - val_loss: 1505.1857\n",
      "Epoch 139/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1473.2303 - val_loss: 1483.1624\n",
      "Epoch 140/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1451.6846 - val_loss: 1461.4331\n",
      "Epoch 141/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1430.4392 - val_loss: 1440.0696\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466/4466 [==============================] - 7s 2ms/step - loss: 1409.5517 - val_loss: 1418.9408\n",
      "Epoch 143/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1388.9251 - val_loss: 1398.2428\n",
      "Epoch 144/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1368.6674 - val_loss: 1377.7802\n",
      "Epoch 145/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1348.7009 - val_loss: 1357.6323\n",
      "Epoch 146/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1329.0272 - val_loss: 1337.8573\n",
      "Epoch 147/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1309.7018 - val_loss: 1318.3231\n",
      "Epoch 148/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1290.6326 - val_loss: 1299.1991\n",
      "Epoch 149/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1271.9344 - val_loss: 1280.2512\n",
      "Epoch 150/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1253.4848 - val_loss: 1261.6742\n",
      "Epoch 151/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1235.3667 - val_loss: 1243.3735\n",
      "Epoch 152/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1217.5343 - val_loss: 1225.4040\n",
      "Epoch 153/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1200.0040 - val_loss: 1207.7409\n",
      "Epoch 154/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1182.7866 - val_loss: 1190.3153\n",
      "Epoch 155/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1165.8337 - val_loss: 1173.2373\n",
      "Epoch 156/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1149.1956 - val_loss: 1156.4310\n",
      "Epoch 157/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 1132.8541 - val_loss: 1139.8766\n",
      "Epoch 158/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1116.7586 - val_loss: 1123.7272\n",
      "Epoch 159/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1101.0183 - val_loss: 1107.7316\n",
      "Epoch 160/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1085.4998 - val_loss: 1092.1105\n",
      "Epoch 161/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1070.2908 - val_loss: 1076.7605\n",
      "Epoch 162/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1055.3694 - val_loss: 1061.6598\n",
      "Epoch 163/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 1040.6999 - val_loss: 1046.8835\n",
      "Epoch 164/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1026.3414 - val_loss: 1032.3088\n",
      "Epoch 165/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 1012.2367 - val_loss: 1018.0225\n",
      "Epoch 166/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 998.3873 - val_loss: 1004.0697\n",
      "Epoch 167/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 984.8324 - val_loss: 990.3699\n",
      "Epoch 168/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 971.5359 - val_loss: 976.9516\n",
      "Epoch 169/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 958.5156 - val_loss: 963.7620\n",
      "Epoch 170/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 945.7473 - val_loss: 950.8421\n",
      "Epoch 171/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 933.2424 - val_loss: 938.1828\n",
      "Epoch 172/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 920.9999 - val_loss: 925.7787\n",
      "Epoch 173/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 909.0061 - val_loss: 913.6464\n",
      "Epoch 174/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 897.2767 - val_loss: 901.7545\n",
      "Epoch 175/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 885.7935 - val_loss: 890.1169\n",
      "Epoch 176/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 874.5610 - val_loss: 878.7290\n",
      "Epoch 177/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 863.5700 - val_loss: 867.6036\n",
      "Epoch 178/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 852.8373 - val_loss: 856.7021\n",
      "Epoch 179/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 842.3327 - val_loss: 846.0736\n",
      "Epoch 180/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 832.0782 - val_loss: 835.6807\n",
      "Epoch 181/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 822.0671 - val_loss: 825.5101\n",
      "Epoch 182/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 812.2999 - val_loss: 815.5215\n",
      "Epoch 183/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 802.7441 - val_loss: 805.8130\n",
      "Epoch 184/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 793.4040 - val_loss: 796.4159\n",
      "Epoch 185/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 784.3405 - val_loss: 787.1512\n",
      "Epoch 186/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 775.4574 - val_loss: 778.1722\n",
      "Epoch 187/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 766.8210 - val_loss: 769.3881\n",
      "Epoch 188/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 758.3972 - val_loss: 760.8180\n",
      "Epoch 189/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 750.1944 - val_loss: 752.4645\n",
      "Epoch 190/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 742.2191 - val_loss: 744.2775\n",
      "Epoch 191/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 734.4234 - val_loss: 736.3850\n",
      "Epoch 192/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 726.8584 - val_loss: 728.6908\n",
      "Epoch 193/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 719.5009 - val_loss: 721.1788\n",
      "Epoch 194/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 712.3420 - val_loss: 713.8831\n",
      "Epoch 195/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 705.3859 - val_loss: 706.7848\n",
      "Epoch 196/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 698.6279 - val_loss: 699.8859\n",
      "Epoch 197/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 692.0511 - val_loss: 693.2322\n",
      "Epoch 198/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 685.7084 - val_loss: 686.6637\n",
      "Epoch 199/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 679.5110 - val_loss: 680.3513\n",
      "Epoch 200/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 673.5141 - val_loss: 674.2433\n",
      "Epoch 201/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 667.7089 - val_loss: 668.2963\n",
      "Epoch 202/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 662.0885 - val_loss: 662.4965\n",
      "Epoch 203/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 656.6224 - val_loss: 656.9410\n",
      "Epoch 204/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 651.3650 - val_loss: 651.4995\n",
      "Epoch 205/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 646.2610 - val_loss: 646.2535\n",
      "Epoch 206/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 641.3240 - val_loss: 641.2025\n",
      "Epoch 207/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 636.5540 - val_loss: 636.3278\n",
      "Epoch 208/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 631.9692 - val_loss: 631.5612\n",
      "Epoch 209/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 627.5125 - val_loss: 627.0085\n",
      "Epoch 210/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 623.2345 - val_loss: 622.5818\n",
      "Epoch 211/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 619.1052 - val_loss: 618.3083\n",
      "Epoch 212/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 615.1134 - val_loss: 614.2368\n",
      "Epoch 213/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 611.2864 - val_loss: 610.2888\n",
      "Epoch 214/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 607.6185 - val_loss: 606.4108\n",
      "Epoch 215/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 604.0481 - val_loss: 602.7571\n",
      "Epoch 216/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 600.6433 - val_loss: 599.2373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 597.3749 - val_loss: 595.8384\n",
      "Epoch 218/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 594.2422 - val_loss: 592.5542\n",
      "Epoch 219/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 591.2190 - val_loss: 589.4398\n",
      "Epoch 220/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 588.3391 - val_loss: 586.4243\n",
      "Epoch 221/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 585.5679 - val_loss: 583.5678\n",
      "Epoch 222/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 582.9356 - val_loss: 580.7865\n",
      "Epoch 223/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 580.3941 - val_loss: 578.1670\n",
      "Epoch 224/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 577.9918 - val_loss: 575.6097\n",
      "Epoch 225/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 575.6826 - val_loss: 573.1716\n",
      "Epoch 226/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 573.4749 - val_loss: 570.8728\n",
      "Epoch 227/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 571.3852 - val_loss: 568.6635\n",
      "Epoch 228/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 569.4035 - val_loss: 566.5156\n",
      "Epoch 229/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 567.4779 - val_loss: 564.5741\n",
      "Epoch 230/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 565.7017 - val_loss: 562.6200\n",
      "Epoch 231/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 563.9699 - val_loss: 560.8275\n",
      "Epoch 232/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 562.3606 - val_loss: 559.0675\n",
      "Epoch 233/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 560.8125 - val_loss: 557.4380\n",
      "Epoch 234/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 559.3634 - val_loss: 555.8736\n",
      "Epoch 235/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 557.9855 - val_loss: 554.3940\n",
      "Epoch 236/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 556.6846 - val_loss: 552.9950\n",
      "Epoch 237/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 555.4575 - val_loss: 551.6723\n",
      "Epoch 238/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 554.3029 - val_loss: 550.4137\n",
      "Epoch 239/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 553.2174 - val_loss: 549.2228\n",
      "Epoch 240/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 552.1939 - val_loss: 548.1025\n",
      "Epoch 241/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 551.2288 - val_loss: 547.0622\n",
      "Epoch 242/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 550.3348 - val_loss: 546.0562\n",
      "Epoch 243/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 549.4919 - val_loss: 545.1077\n",
      "Epoch 244/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 548.6927 - val_loss: 544.2536\n",
      "Epoch 245/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 547.9623 - val_loss: 543.4205\n",
      "Epoch 246/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 547.2714 - val_loss: 542.6505\n",
      "Epoch 247/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 546.6302 - val_loss: 541.9195\n",
      "Epoch 248/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 546.0276 - val_loss: 541.2543\n",
      "Epoch 249/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 545.4775 - val_loss: 540.6008\n",
      "Epoch 250/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 544.9544 - val_loss: 540.0167\n",
      "Epoch 251/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 544.4810 - val_loss: 539.4517\n",
      "Epoch 252/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 544.0400 - val_loss: 538.9290\n",
      "Epoch 253/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 543.6340 - val_loss: 538.4450\n",
      "Epoch 254/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 543.2520 - val_loss: 538.0195\n",
      "Epoch 255/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 542.9134 - val_loss: 537.5880\n",
      "Epoch 256/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 542.5875 - val_loss: 537.2192\n",
      "Epoch 257/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.2991 - val_loss: 536.8566\n",
      "Epoch 258/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 542.0336 - val_loss: 536.5117\n",
      "Epoch 259/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.7836 - val_loss: 536.2213\n",
      "Epoch 260/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.5640 - val_loss: 535.9238\n",
      "Epoch 261/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.3597 - val_loss: 535.6596\n",
      "Epoch 262/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 541.1727 - val_loss: 535.4240\n",
      "Epoch 263/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 541.0054 - val_loss: 535.2066\n",
      "Epoch 264/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.8566 - val_loss: 534.9947\n",
      "Epoch 265/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.7176 - val_loss: 534.8041\n",
      "Epoch 266/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.5901 - val_loss: 534.6526\n",
      "Epoch 267/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.4815 - val_loss: 534.4779\n",
      "Epoch 268/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.3779 - val_loss: 534.3323\n",
      "Epoch 269/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.2930 - val_loss: 534.1825\n",
      "Epoch 270/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 540.2033 - val_loss: 534.0839\n",
      "Epoch 271/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.1349 - val_loss: 533.9709\n",
      "Epoch 272/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.0722 - val_loss: 533.8612\n",
      "Epoch 273/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 540.0115 - val_loss: 533.7765\n",
      "Epoch 274/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.9630 - val_loss: 533.6916\n",
      "Epoch 275/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.9178 - val_loss: 533.6088\n",
      "Epoch 276/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 539.8773 - val_loss: 533.5334\n",
      "Epoch 277/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 539.8414 - val_loss: 533.4747\n",
      "Epoch 278/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.8114 - val_loss: 533.4121\n",
      "Epoch 279/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.7831 - val_loss: 533.3682\n",
      "Epoch 280/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.7607 - val_loss: 533.3128\n",
      "Epoch 281/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.7423 - val_loss: 533.2594\n",
      "Epoch 282/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.7204 - val_loss: 533.2254\n",
      "Epoch 283/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.7076 - val_loss: 533.1894\n",
      "Epoch 284/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6944 - val_loss: 533.1506\n",
      "Epoch 285/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6793 - val_loss: 533.1309\n",
      "Epoch 286/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6699 - val_loss: 533.1018\n",
      "Epoch 287/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6610 - val_loss: 533.0811\n",
      "Epoch 288/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6541 - val_loss: 533.0537\n",
      "Epoch 289/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6466 - val_loss: 533.0325\n",
      "Epoch 290/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6416 - val_loss: 533.0120\n",
      "Epoch 291/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6351 - val_loss: 532.9997\n",
      "Epoch 292/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6315 - val_loss: 532.9778\n",
      "Epoch 293/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6278 - val_loss: 532.9650\n",
      "Epoch 294/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6241 - val_loss: 532.9591\n",
      "Epoch 295/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6228 - val_loss: 532.9457\n",
      "Epoch 296/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6190 - val_loss: 532.9317\n",
      "Epoch 297/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6170 - val_loss: 532.9256\n",
      "Epoch 298/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6164 - val_loss: 532.9111\n",
      "Epoch 299/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6128 - val_loss: 532.9111\n",
      "Epoch 300/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6116 - val_loss: 532.9025\n",
      "Epoch 301/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6102 - val_loss: 532.8917\n",
      "Epoch 302/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6093 - val_loss: 532.8836\n",
      "Epoch 303/500\n",
      "4466/4466 [==============================] - 6s 1ms/step - loss: 539.6121 - val_loss: 532.8716\n",
      "Epoch 304/500\n",
      "4466/4466 [==============================] - 7s 2ms/step - loss: 539.6079 - val_loss: 532.8750\n",
      "Epoch 305/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6067 - val_loss: 532.8750\n",
      "Epoch 306/500\n",
      "4466/4466 [==============================] - 7s 1ms/step - loss: 539.6060 - val_loss: 532.8691\n",
      "Epoch 00306: early stopping\n"
     ]
    }
   ],
   "source": [
    "for train_idx, val_idx in splits.split(X_train):\n",
    "    X_train_cv = X_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    X_valid_cv = X_train[val_idx]\n",
    "    y_valid_cv = y_train[val_idx]\n",
    "    y_train_cv = y_train_cv[:,:,np.newaxis]\n",
    "    y_valid_cv = y_valid_cv[:,:,np.newaxis]\n",
    "    model = buildManyToManyModel(X_train_cv.shape)\n",
    "    callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.1, patience=10, verbose=10, mode=\"auto\")\n",
    "    history = model.fit(X_train_cv, y_train_cv, epochs=500, batch_size=128, validation_data=(X_valid_cv, y_valid_cv), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(history.history['loss'],'b')\n",
    "plt.plot(history.history['val_loss'],'r')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543.9387292990373"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,predictions[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007518498144947196"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,predictions[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.342700505384251e-06"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,predictions[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "* From the metrics, we can see the result is not very good. There may be some reasons: (1) Features are not enough to predict the AQI (2) Predict the next 5 day AQI from previous 5 days may not be best way since the period is too long for my model to learn more information \n",
    "* Despite capability of predict accurately, my model is trained properly since the training, validation, and test loss are very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
